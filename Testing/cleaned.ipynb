{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d7d2e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f6f3f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8632f9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Project\\News_Majority\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "import trafilatura\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "# import io\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "import os\n",
    "from youtube_transcript_api.proxies import WebshareProxyConfig, GenericProxyConfig\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbf278",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d868a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Installing spaCy model...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2cd40c",
   "metadata": {},
   "source": [
    "## Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb502e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"ProsusAI/finbert\",\n",
    "    tokenizer=\"ProsusAI/finbert\"\n",
    ")\n",
    "\n",
    "def get_text_sentiment_score(text: str, max_chars=512) -> float:\n",
    "    if not text or not text.strip():\n",
    "        return 0.0\n",
    "\n",
    "    chunks = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
    "    scores = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        result = sentiment_analyzer(chunk)[0]\n",
    "        label = result[\"label\"].upper()\n",
    "        score = float(result[\"score\"])\n",
    "\n",
    "        if \"POS\" in label:\n",
    "            scores.append(score)\n",
    "        elif \"NEG\" in label:\n",
    "            scores.append(-score)\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "\n",
    "    return sum(scores) / len(scores) if scores else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b072542",
   "metadata": {},
   "source": [
    "## Entity Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b44139",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SENTENCES = 1\n",
    "TICKER_LIST_PATH = Path(\"tickers.csv\")  # optional: columns ticker,name\n",
    "\n",
    "TICKER_RE = re.compile(r\"(?<![A-Z])\\$?[A-Z]{2,5}(?![A-Z])\")\n",
    "TICKER_STOP = {\n",
    "    \"A\", \"AN\", \"AND\", \"ARE\", \"AS\", \"AT\", \"BE\", \"BUT\", \"BY\", \"CAN\", \"CO\", \"FOR\",\n",
    "    \"FROM\", \"HAS\", \"HAVE\", \"IN\", \"IS\", \"IT\", \"ITS\", \"NOT\", \"OF\", \"ON\", \"OR\",\n",
    "    \"THE\", \"TO\", \"WAS\", \"WERE\", \"WILL\", \"WITH\",\n",
    "}\n",
    "\n",
    "ENTITY_ALIASES = {\n",
    "    # companies\n",
    "    \"meta\": \"META\",\n",
    "    \"facebook\": \"META\",\n",
    "\n",
    "    \"google\": \"GOOGL\",\n",
    "    \"alphabet\": \"GOOGL\",\n",
    "\n",
    "    \"apple\": \"AAPL\",\n",
    "    \"amazon\": \"AMZN\",\n",
    "    \"microsoft\": \"MSFT\",\n",
    "\n",
    "    # institutions\n",
    "    \"fed\": \"Federal Reserve\",\n",
    "    \"federal reserve\": \"Federal Reserve\",\n",
    "    \"doj\": \"Department of Justice\",\n",
    "    \"department of justice\": \"Department of Justice\",\n",
    "    \"supreme court\": \"Supreme Court\",\n",
    "    \"cnn\": \"CNN\",\n",
    "}\n",
    "\n",
    "SECTOR_KEYWORDS = {\n",
    "    \"Technology\": [\"tech\", \"software\", \"technology\", \"cloud\", \"ai\", \"artificial intelligence\",\n",
    "                   \"chip\", \"semiconductor\", \"digital\", \"platform\", \"app\", \"data\", \"cyber\"],\n",
    "    \"Finance\": [\"bank\", \"financial\", \"finance\", \"investment\", \"trading\", \"market\",\n",
    "                \"stock\", \"equity\", \"bond\", \"credit\", \"lending\", \"mortgage\"],\n",
    "    \"Healthcare\": [\"health\", \"medical\", \"pharmaceutical\", \"drug\", \"biotech\", \"hospital\",\n",
    "                    \"treatment\", \"patient\", \"fda\", \"clinical\", \"therapy\"],\n",
    "    \"Energy\": [\"oil\", \"gas\", \"energy\", \"petroleum\", \"renewable\", \"solar\", \"wind\",\n",
    "               \"electric\", \"power\", \"fuel\", \"drilling\", \"crude\"],\n",
    "    \"Retail\": [\"retail\", \"store\", \"shopping\", \"consumer\", \"e-commerce\", \"online shopping\",\n",
    "               \"merchandise\", \"sales\", \"retailer\"],\n",
    "    \"Automotive\": [\"car\", \"automotive\", \"vehicle\", \"auto\", \"truck\", \"electric vehicle\",\n",
    "                   \"ev\", \"manufacturing\", \"tesla\"],\n",
    "    \"Real Estate\": [\"real estate\", \"property\", \"housing\", \"construction\", \"mortgage\",\n",
    "                    \"development\", \"reit\"],\n",
    "    \"Telecommunications\": [\"telecom\", \"communication\", \"wireless\", \"5g\", \"network\", \"internet\"],\n",
    "    \"Aerospace\": [\"aerospace\", \"aircraft\", \"defense\", \"boeing\", \"space\"],\n",
    "    \"Consumer Goods\": [\"consumer goods\", \"packaged goods\", \"cpg\"],\n",
    "}\n",
    "\n",
    "def normalize_company_name(name):\n",
    "    return name.lower().replace(\"inc.\", \"\").replace(\"corp.\", \"\").replace(\"corporation\", \"\").strip()\n",
    "\n",
    "def extract_article_text(url: str) -> str | None:\n",
    "    downloaded = trafilatura.fetch_url(url)\n",
    "    if not downloaded:\n",
    "        return None\n",
    "\n",
    "    text = trafilatura.extract(\n",
    "        downloaded,\n",
    "        include_comments=False,\n",
    "        include_tables=False,\n",
    "        include_formatting=False\n",
    "    )\n",
    "    return text\n",
    "\n",
    "def load_ticker_map(path: Path):\n",
    "    ticker_to_name = {}\n",
    "    name_to_ticker = {}\n",
    "    if not path.exists():\n",
    "        return ticker_to_name, name_to_ticker\n",
    "\n",
    "    with path.open(\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            ticker = (row.get(\"ticker\") or \"\").strip().upper()\n",
    "            name = (row.get(\"name\") or \"\").strip()\n",
    "            if not ticker or not name:\n",
    "                continue\n",
    "            ticker_to_name[ticker] = name\n",
    "            name_to_ticker[normalize_company_name(name)] = ticker\n",
    "\n",
    "    return ticker_to_name, name_to_ticker\n",
    "\n",
    "\n",
    "ticker_to_name, name_to_ticker = load_ticker_map(TICKER_LIST_PATH)\n",
    "\n",
    "\n",
    "def fetch_articles(feed_url, max_items=30):\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    articles = []\n",
    "    for entry in feed.entries[:max_items]:\n",
    "        text = extract_article_text(entry.link)\n",
    "        if not text:\n",
    "            continue\n",
    "        articles.append({\n",
    "            \"title\": entry.title,\n",
    "            \"url\": entry.link,\n",
    "            \"published\": entry.get(\"published\"),\n",
    "            \"text\": text,\n",
    "        })\n",
    "    return articles\n",
    "\n",
    "\n",
    "def get_tickers(text):\n",
    "    tickers = set()\n",
    "    for m in TICKER_RE.findall(text):\n",
    "        t = m.replace(\"$\", \"\").upper()\n",
    "        if t in TICKER_STOP:\n",
    "            continue\n",
    "        if ticker_to_name and t not in ticker_to_name:\n",
    "            continue\n",
    "        tickers.add(t)\n",
    "\n",
    "    return list(tickers)\n",
    "\n",
    "def get_companies(doc):\n",
    "    mapped = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ != \"ORG\":\n",
    "            continue\n",
    "        key = normalize_company_name(ent.text)\n",
    "        if key in name_to_ticker:\n",
    "            mapped.append(name_to_ticker[key])   # return ticker\n",
    "        else:\n",
    "            mapped.append(ent.text)\n",
    "    return mapped\n",
    "\n",
    "\n",
    "def get_sectors(text_lower):\n",
    "    return [\n",
    "        sector for sector, keywords in SECTOR_KEYWORDS.items()\n",
    "        if any(kw in text_lower for kw in keywords)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ce0b7",
   "metadata": {},
   "source": [
    "## Youtube Data Api Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6f0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "YOUTUBE_API_KEY = os.getenv(\"API_KEY\")\n",
    "CHANNEL_ID = \"UCrp_UI8XtuYfpiqluWLD7Lw\"  # CNBC channel\n",
    "MAX_VIDEOS = 100\n",
    "\n",
    "def fetch_youtube_videos_with_api(channel_id, api_key, max_results=100):\n",
    "    \"\"\"Fetch YouTube videos using Data API (no transcripts needed)\"\"\"\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "    uploads_playlist_id = None\n",
    "    \n",
    "    print(f\"Fetching videos from channel {channel_id}...\")\n",
    "    \n",
    "    while len(videos) < max_results:\n",
    "        try:\n",
    "            # First, get the uploads playlist ID for the channel\n",
    "            if uploads_playlist_id is None:  # Only need to do this once\n",
    "                channel_response = youtube.channels().list(\n",
    "                    part='contentDetails',\n",
    "                    id=channel_id\n",
    "                ).execute()\n",
    "                \n",
    "                if not channel_response.get('items'):\n",
    "                    print(f\"âŒ Channel {channel_id} not found\")\n",
    "                    break\n",
    "                \n",
    "                uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "            \n",
    "            # Get videos from uploads playlist\n",
    "            if uploads_playlist_id:\n",
    "                request = youtube.playlistItems().list(\n",
    "                    part='snippet,contentDetails',\n",
    "                    playlistId=uploads_playlist_id,\n",
    "                    maxResults=min(max_results, max_results - len(videos)),\n",
    "                    pageToken=next_page_token\n",
    "                )\n",
    "            else:\n",
    "                # Fallback: search for videos from channel\n",
    "                request = youtube.search().list(\n",
    "                    part='snippet',\n",
    "                    channelId=channel_id,\n",
    "                    type='video',\n",
    "                    maxResults=min(max_results, max_results - len(videos)),\n",
    "                    pageToken=next_page_token,\n",
    "                    order='date'\n",
    "                )\n",
    "            \n",
    "            response = request.execute()\n",
    "            \n",
    "            # Get video IDs\n",
    "            video_ids = []\n",
    "            for item in response['items']:\n",
    "                if 'contentDetails' in item:\n",
    "                    video_ids.append(item['contentDetails']['videoId'])\n",
    "                elif 'id' in item and 'videoId' in item['id']:\n",
    "                    video_ids.append(item['id']['videoId'])\n",
    "            \n",
    "            # Get detailed video information\n",
    "            if video_ids:\n",
    "                video_details = youtube.videos().list(\n",
    "                    part='snippet,statistics',\n",
    "                    id=','.join(video_ids)\n",
    "                ).execute()\n",
    "                \n",
    "                for item in video_details['items']:\n",
    "                    snippet = item['snippet']\n",
    "                    videos.append({\n",
    "                        'title': snippet.get('title', ''),\n",
    "                        'video_id': item['id'],\n",
    "                        'url': f\"https://www.youtube.com/watch?v={item['id']}\",\n",
    "                        'published': snippet.get('publishedAt', ''),\n",
    "                        'published_date': snippet.get('publishedAt', ''),\n",
    "                        'author': snippet.get('channelTitle', ''),\n",
    "                        'summary': snippet.get('description', ''),  # Full description\n",
    "                        'transcript_text': None,  # No transcript (IP banned)\n",
    "                        'view_count': item['statistics'].get('viewCount', 0),\n",
    "                        'like_count': item['statistics'].get('likeCount', 0),\n",
    "                    })\n",
    "            \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "                \n",
    "            print(f\"  Fetched {len(videos)} videos so far...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error fetching videos: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"âœ… Total videos fetched: {len(videos)}\")\n",
    "    return videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293213d",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfcd3d",
   "metadata": {},
   "source": [
    "## Retrieve latest 100 videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d85a61",
   "metadata": {},
   "source": [
    "## Retrieve and cache Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c27c6d",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "print(\"HTTP_PROXY =\", os.environ.get(\"HTTP_PROXY\"))\n",
    "print(\"HTTPS_PROXY =\", os.environ.get(\"HTTPS_PROXY\"))\n",
    "print(\"Proxies seen by requests:\", requests.utils.get_environ_proxies(\"https://www.youtube.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "# URL-encode credentials\n",
    "proxy_user = quote(os.getenv(\"PROXY_USER\"), safe='')\n",
    "proxy_pass = quote(os.getenv(\"PROXY_PASS\"), safe='')\n",
    "\n",
    "# Set rotating proxy globally\n",
    "proxy_url = f\"http://{proxy_user}:{proxy_pass}@p.webshare.io:80\"\n",
    "os.environ['HTTP_PROXY'] = proxy_url\n",
    "os.environ['HTTPS_PROXY'] = proxy_url\n",
    "\n",
    "# Test rotation by checking your IP multiple times\n",
    "print(\"Testing proxy rotation...\")\n",
    "for i in range(5):\n",
    "    try:\n",
    "        response = requests.get('https://api.ipify.org?format=json', \n",
    "                               proxies={'http': proxy_url, 'https': proxy_url},\n",
    "                               timeout=10)\n",
    "        ip = response.json().get('ip')\n",
    "        print(f\"Request {i+1}: IP = {ip}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request {i+1}: Error = {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3abb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchedTranscript(snippets=[FetchedTranscriptSnippet(text='THAT TIME. I STEPPED UP TO THE', start=16.282, duration=4.271), FetchedTranscriptSnippet(text='PLATE AND SAM. AND THEN THE', start=18.051, duration=3.804), FetchedTranscriptSnippet(text='LIGHTNING ROUND IS OVER. ARE', start=20.587, duration=3.403), FetchedTranscriptSnippet(text='YOU READY FOR THE LIGHTNING', start=21.888, duration=3.904), FetchedTranscriptSnippet(text=\"ROUND? WE'RE GOING TO START\", start=24.024, duration=6.172), FetchedTranscriptSnippet(text='WITH JIM IN RHODE ISLAND. JIM.', start=25.825, duration=5.806), FetchedTranscriptSnippet(text=\">> HEY JIM CRAMER, IT'S AN\", start=30.23, duration=2.836), FetchedTranscriptSnippet(text='ABSOLUTE PLEASURE TO SPEAK WITH', start=31.664, duration=2.103), FetchedTranscriptSnippet(text='YOU.', start=33.099, duration=1.669), FetchedTranscriptSnippet(text='>> RIGHT BACK AT.', start=33.8, duration=2.569), FetchedTranscriptSnippet(text='>> YOU MY NEW ENGLAND MY NEW', start=34.801, duration=4.004), FetchedTranscriptSnippet(text='ENGLAND PATRIOTS TO PLAY IN. MY', start=36.403, duration=3.47), FetchedTranscriptSnippet(text='CONDOLENCES TO YOU AND YOUR', start=38.838, duration=2.503), FetchedTranscriptSnippet(text='PHILADELPHIA EAGLES.', start=39.906, duration=3.27), FetchedTranscriptSnippet(text='>> I VERY MUCH APPRECIATE THAT.', start=41.374, duration=2.903), FetchedTranscriptSnippet(text=\"IT'S BEEN VERY SOUL SEARCHING\", start=43.209, duration=2.736), FetchedTranscriptSnippet(text='TIME FOR ME. AND I DO WISH YOU', start=44.31, duration=3.471), FetchedTranscriptSnippet(text='THE BEST OF LUCK FOR THE', start=45.979, duration=2.903), FetchedTranscriptSnippet(text='PATRIOTS. HOW CAN I HELP?', start=47.814, duration=2.236), FetchedTranscriptSnippet(text='>> THANK YOU, MY FRIEND. HEY,', start=48.915, duration=2.87), FetchedTranscriptSnippet(text=\"WE'VE HAD A 35 YEAR\", start=50.083, duration=2.235), FetchedTranscriptSnippet(text=\"RELATIONSHIP THAT YOU'RE\", start=51.818, duration=2.102), FetchedTranscriptSnippet(text='UNAWARE OF. I WAS A NUCLEAR', start=52.352, duration=3.77), FetchedTranscriptSnippet(text='TRAINED SUBMARINER, CAME OUT OF', start=53.953, duration=3.37), FetchedTranscriptSnippet(text='THE NAVY AND GOT A BROKER', start=56.156, duration=3.003), FetchedTranscriptSnippet(text='DEALER TO SPONSOR ME IN NEW', start=57.357, duration=3.537), FetchedTranscriptSnippet(text='JERSEY IN 1991. WOW.', start=59.192, duration=3.07), FetchedTranscriptSnippet(text='>> SO YOU SO GREAT.', start=60.927, duration=3.604), FetchedTranscriptSnippet(text='>> YOU AND YOU AND CNBC HAVE', start=62.429, duration=3.77), FetchedTranscriptSnippet(text='BEEN PART OF MY LIFE SINCE', start=64.564, duration=3.57), FetchedTranscriptSnippet(text='KUDLOW AND CRAMER.', start=66.232, duration=2.903), FetchedTranscriptSnippet(text='>> SO LOVE IT.', start=68.168, duration=2.435), FetchedTranscriptSnippet(text=\">> THANK YOU. LET'S HELP. LET'S\", start=69.169, duration=3.57), FetchedTranscriptSnippet(text='HELP EVERYBODY WITH A GREAT', start=70.637, duration=4.271), FetchedTranscriptSnippet(text='DEEP VALUE PLAY. TWO BROTHERS', start=72.772, duration=3.637), FetchedTranscriptSnippet(text='TWO FRIENDS IN RHODE ISLAND', start=74.941, duration=3.203), FetchedTranscriptSnippet(text='STEPHEN WILCOX AND GEORGE', start=76.443, duration=3.603), FetchedTranscriptSnippet(text='BABCOCK. BABCOCK AND WILCOX', start=78.178, duration=5.038), FetchedTranscriptSnippet(text='FORMED IN 1867, SOLD THE STEAM', start=80.08, duration=5.705), FetchedTranscriptSnippet(text='GENERATOR TO MR. TOM EDISON.', start=83.249, duration=3.47), FetchedTranscriptSnippet(text='BOY.', start=85.819, duration=2.102), FetchedTranscriptSnippet(text=\">> YOU KNOW, YOU'RE ABSOLUTELY\", start=86.753, duration=2.202), FetchedTranscriptSnippet(text=\"RIGHT. I'VE GOT TO TELL YOU.\", start=87.954, duration=2.769), FetchedTranscriptSnippet(text='FIRST OF ALL, THANKS FOR', start=88.988, duration=2.903), FetchedTranscriptSnippet(text='WATCHING FOR SO LONG AND BACK.', start=90.757, duration=2.202), FetchedTranscriptSnippet(text='BOM KIM WILCOX. NOW,', start=91.925, duration=2.002), FetchedTranscriptSnippet(text=\"UNFORTUNATELY, IT'S UP 30% FOR\", start=92.992, duration=2.87), FetchedTranscriptSnippet(text='THE YEAR, BUT IT IS A GREAT', start=93.96, duration=3.103), FetchedTranscriptSnippet(text='SPEC ON THE CONSTRUCTION OF', start=95.895, duration=2.836), FetchedTranscriptSnippet(text=\"POWER PLANTS. LET'S WAIT UNTIL\", start=97.097, duration=3.003), FetchedTranscriptSnippet(text='IT GOES DOWN A LITTLE BIT AND', start=98.765, duration=2.969), FetchedTranscriptSnippet(text='THEN PULL THE TRIGGER. AND', start=100.133, duration=2.769), FetchedTranscriptSnippet(text=\"THANK YOU FOR SERVING. LET'S GO\", start=101.768, duration=5.572), FetchedTranscriptSnippet(text='TO LARRY IN NEW JERSEY LARRY.', start=103.536, duration=5.205), FetchedTranscriptSnippet(text='>> BIG JIM, HOW YOU DOING?', start=107.373, duration=2.97), FetchedTranscriptSnippet(text=\">> I'M DOING WELL. LARRY, HOW\", start=108.775, duration=2.502), FetchedTranscriptSnippet(text='YOU BEEN?', start=110.376, duration=2.269), FetchedTranscriptSnippet(text=\">> I'M DOING GREAT. THANKS.\", start=111.311, duration=3.57), FetchedTranscriptSnippet(text='FIRST TIME CALLER, LONG TIME', start=112.679, duration=5.806), FetchedTranscriptSnippet(text='LISTENER. CALLING ABOUT', start=114.914, duration=5.372), FetchedTranscriptSnippet(text='MOUNTAIN NORTON.', start=118.518, duration=3.637), FetchedTranscriptSnippet(text='>> I INITIALLY SAID IT WAS GOOD', start=120.32, duration=3.003), FetchedTranscriptSnippet(text='THAT IT WAS ABLE TO RETRACT', start=122.188, duration=2.87), FetchedTranscriptSnippet(text='THAT. THANK HEAVENS THIS STOCK', start=123.356, duration=2.97), FetchedTranscriptSnippet(text='IS JUST AWFUL. I CANNOT BELIEVE', start=125.091, duration=3.07), FetchedTranscriptSnippet(text='I MEAN, THEY GOT TO MAKE THEY', start=126.359, duration=3.003), FetchedTranscriptSnippet(text='HAVE TO MAKE MONEY. THEY HAVE', start=128.194, duration=3.037), FetchedTranscriptSnippet(text=\"TO MAKE MONEY OR ELSE IT WON'T\", start=129.963, duration=2.402), FetchedTranscriptSnippet(text='TURN AROUND. IT BECAME PUBLIC', start=131.264, duration=2.936), FetchedTranscriptSnippet(text='IN A VERY EXCITING TIME AND IT', start=132.966, duration=4.037), FetchedTranscriptSnippet(text='IS GOING LOWER WITHOUT EARNINGS', start=134.534, duration=4.438), FetchedTranscriptSnippet(text='PER SHARE. AND THAT, LADIES AND', start=137.036, duration=3.304), FetchedTranscriptSnippet(text='GENTLEMEN, IS THE CONCLUSION OF', start=139.005, duration=3.937), FetchedTranscriptSnippet(text='THE LIGHTNING ROUND.', start=140.373, duration=3.737), FetchedTranscriptSnippet(text='>> THE LIGHTNING ROUND IS', start=143.143, duration=4.604), FetchedTranscriptSnippet(text='SPONSORED BY CHARLES SCHWAB.', start=144.144, duration=5.071), FetchedTranscriptSnippet(text='COMING UP, DID SELLING SHARES', start=147.78, duration=3.571), FetchedTranscriptSnippet(text='OF WELLS FARGO FOR THE', start=149.682, duration=3.304), FetchedTranscriptSnippet(text='CHARITABLE TRUST CHANGE', start=151.384, duration=3.37), FetchedTranscriptSnippet(text=\"CRAMER'S DON'T TRADE\", start=153.019, duration=1.735)], video_id='wN2s5uGh1YQ', language='English - DTVCC1', language_code='en', is_generated=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytt_api = YouTubeTranscriptApi(\n",
    "    proxy_config=WebshareProxyConfig(\n",
    "        proxy_username = os.getenv(\"PROXY_USER\"),\n",
    "        proxy_password = os.getenv(\"PROXY_PASS\"),\n",
    "    )\n",
    ")\n",
    "transcript = ytt_api.fetch('wN2s5uGh1YQ')\n",
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c0f03",
   "metadata": {},
   "source": [
    "### Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c444da",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT_CACHE_PATH = Path('daily_transcripts.json')\n",
    "MAX_CACHE_SIZE = 100  # Maximum number of videos to keep in cache\n",
    "\n",
    "def load_transcript_cache(path):\n",
    "    if path.exists():\n",
    "        try:\n",
    "            content = path.read_text(encoding='utf-8')\n",
    "            if content.strip():\n",
    "                return json.loads(content)\n",
    "            else:\n",
    "                print(\"âš ï¸  Cache file is empty, starting fresh\")\n",
    "                return {}\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"âš ï¸  Cache file is corrupted: {e}\")\n",
    "            print(\"   Starting with fresh cache\")\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_transcript_cache(path, cache):\n",
    "    try:\n",
    "        path.write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Failed to save cache: {e}\")\n",
    "\n",
    "def fetch_transcript_with_backoff(video_id, max_retries=3):\n",
    "    \"\"\"\n",
    "    Fetch transcript with exponential backoff and jitter.\n",
    "    No proxy - relies on longer delays to avoid rate limits.\n",
    "    \"\"\"\n",
    "    base_delay = 5.0  # Longer initial delay without proxy\n",
    "    \n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            # Add random delay before each request (rate limit avoidance)\n",
    "            jitter = random.uniform(2, 5)\n",
    "            if attempt > 1:\n",
    "                time.sleep(jitter)\n",
    "            ytt_api = YouTubeTranscriptApi(\n",
    "                proxy_config=WebshareProxyConfig(\n",
    "                    proxy_username = os.getenv(\"PROXY_USER\"),\n",
    "                    proxy_password = os.getenv(\"PROXY_PASS\"),\n",
    "                )\n",
    "            )\n",
    "            transcript = ytt_api.fetch(video_id)\n",
    "            return ' '.join([seg.text for seg in transcript])\n",
    "            \n",
    "        except (TranscriptsDisabled, NoTranscriptFound):\n",
    "            # These are not rate limits, just unavailable transcripts\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e).lower()\n",
    "            \n",
    "            # Check for rate limit indicators\n",
    "            if any(indicator in error_msg for indicator in ['429', 'too many requests', 'rate limit', 'forbidden', '403']):\n",
    "                wait_time = base_delay * (2 ** (attempt - 1)) + random.uniform(5, 15)\n",
    "                print(f\"âš ï¸  Rate limit detected (attempt {attempt}/{max_retries})\")\n",
    "                print(f\"   Waiting {wait_time:.1f}s before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            \n",
    "            # Other errors\n",
    "            print(f\"Attempt {attempt} failed for {video_id}: {type(e).__name__}: {str(e)[:100]}\")\n",
    "            if attempt == max_retries:\n",
    "                return None\n",
    "            \n",
    "            # Exponential backoff for other errors\n",
    "            wait_time = base_delay * (1.5 ** attempt) + random.uniform(1, 3)\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def attach_transcripts(videos, cache_path=TRANSCRIPT_CACHE_PATH, max_cache_size=MAX_CACHE_SIZE, delay_between_requests=3.0):\n",
    "    \"\"\"\n",
    "    Attach transcripts to videos with aggressive rate limit avoidance.\n",
    "    \n",
    "    Args:\n",
    "        videos: List of video dictionaries\n",
    "        cache_path: Path to cache file\n",
    "        max_cache_size: Maximum number of videos to keep in cache\n",
    "        delay_between_requests: Base delay between requests in seconds (default: 3.0)\n",
    "    \"\"\"\n",
    "    latest_ids = [v.get('video_id') for v in videos if v.get('video_id')]\n",
    "    total_videos = len(latest_ids)\n",
    "    print(f\"\\nðŸ“ Processing {total_videos} videos for transcripts...\\n\")\n",
    "    print(f\"â±ï¸  Using delays to avoid rate limits (no proxy)\\n\")\n",
    "\n",
    "    # Load cache\n",
    "    cache = load_transcript_cache(cache_path)\n",
    "    old_cache_size = len(cache)\n",
    "    \n",
    "    # Create ordered list: newest videos first\n",
    "    all_video_ids = latest_ids.copy()\n",
    "    \n",
    "    # Add old cached videos that aren't in the new list\n",
    "    for old_vid in cache.keys():\n",
    "        if old_vid not in all_video_ids:\n",
    "            all_video_ids.append(old_vid)\n",
    "    \n",
    "    # Keep only the newest MAX_CACHE_SIZE videos\n",
    "    videos_to_keep = all_video_ids[:max_cache_size]\n",
    "    \n",
    "    # Filter cache\n",
    "    filtered_cache = {vid: cache[vid] for vid in videos_to_keep if vid in cache}\n",
    "    removed_count = old_cache_size - len(filtered_cache)\n",
    "    \n",
    "    print(f\"ðŸ“¦ Cache status: {old_cache_size} total â†’ keeping {len(filtered_cache)} (removed {removed_count} oldest)\\n\")\n",
    "    \n",
    "    cache = filtered_cache\n",
    "\n",
    "    success_count = 0\n",
    "    failed_count = 0\n",
    "    cached_count = 0\n",
    "    actual_idx = 0\n",
    "\n",
    "    for idx, video in enumerate(videos, start=1):\n",
    "        vid = video.get('video_id')\n",
    "        if not vid:\n",
    "            continue\n",
    "        \n",
    "        actual_idx = idx\n",
    "        \n",
    "        # Check cache first\n",
    "        if vid in cache:\n",
    "            video['transcript_text'] = cache[vid]\n",
    "            cached_count += 1\n",
    "            print(f\"[{idx}/{total_videos}] âœ“ Cached: {vid} - {video.get('title', 'N/A')[:50]}\")\n",
    "            if cache[vid]:\n",
    "                print(f\"  Preview: {cache[vid][:150]}...\\n\")\n",
    "            continue\n",
    "        \n",
    "        # Add delay between requests to avoid rate limits\n",
    "        delay = delay_between_requests + random.uniform(1, 3)\n",
    "        print(f\"[{idx}/{total_videos}] Fetching: {vid} (waiting {delay:.1f}s)...\")\n",
    "        time.sleep(delay)\n",
    "        \n",
    "        # Fetch transcript\n",
    "        try:\n",
    "            transcript_text = fetch_transcript_with_backoff(vid)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Unexpected error: {e}\")\n",
    "            transcript_text = None\n",
    "        \n",
    "        video['transcript_text'] = transcript_text\n",
    "        cache[vid] = transcript_text\n",
    "        \n",
    "        if transcript_text:\n",
    "            success_count += 1\n",
    "            print(f\"âœ“ Success: {video.get('title', 'N/A')[:50]}\")\n",
    "            print(f\"  Preview: {transcript_text[:150]}...\\n\")\n",
    "        else:\n",
    "            failed_count += 1\n",
    "            print(f\"âœ— Failed/No transcript: {video.get('title', 'N/A')[:50]}\\n\")\n",
    "        \n",
    "        # Save cache periodically\n",
    "        if idx % 10 == 0:\n",
    "            save_transcript_cache(cache_path, cache)\n",
    "            print(f\"  ðŸ’¾ Cache saved at {idx} videos\\n\")\n",
    "\n",
    "    # Final save\n",
    "    save_transcript_cache(cache_path, cache)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Summary:\")\n",
    "    print(f\"  âœ“ Successfully fetched: {success_count}\")\n",
    "    print(f\"  âœ“ From cache: {cached_count}\")\n",
    "    print(f\"  âœ— Failed/No transcript: {failed_count}\")\n",
    "    print(f\"  Total processed: {actual_idx}/{total_videos}\")\n",
    "    print(f\"  ðŸ“¦ Final cache size: {len(cache)}/{max_cache_size}\")\n",
    "    print()\n",
    "    \n",
    "    return videos\n",
    "\n",
    "def refresh_transcripts_in_dict(videos, cache_path=Path('daily_transcripts.json')):\n",
    "    \"\"\"Refresh transcript data from cache file\"\"\"\n",
    "    if not cache_path.exists():\n",
    "        return videos\n",
    "    cache = json.loads(cache_path.read_text(encoding='utf-8'))\n",
    "    updated = 0\n",
    "    for video in videos:\n",
    "        vid = video.get('video_id')\n",
    "        if not vid:\n",
    "            continue\n",
    "        cached_value = cache.get(vid)\n",
    "        if cached_value is not None:\n",
    "            if video.get('transcript_text') != cached_value:\n",
    "                video['transcript_text'] = cached_value\n",
    "                updated += 1\n",
    "    print(f'Overwrote {updated} transcripts from cache')\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8575db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching videos from channel UCrp_UI8XtuYfpiqluWLD7Lw...\n",
      "  Fetched 50 videos so far...\n",
      "  Fetched 100 videos so far...\n",
      "âœ… Total videos fetched: 100\n"
     ]
    }
   ],
   "source": [
    "youtube_videos_api = fetch_youtube_videos_with_api(CHANNEL_ID, YOUTUBE_API_KEY, max_results=MAX_VIDEOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d570f82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Processing 100 videos for transcripts...\n",
      "\n",
      "â±ï¸  Using delays to avoid rate limits (no proxy)\n",
      "\n",
      "ðŸ“¦ Cache status: 10 total â†’ keeping 3 (removed 7 oldest)\n",
      "\n",
      "[1/100] Fetching: fiN4riKW1Hs (waiting 6.8s)...\n",
      "âœ“ Success: Mad Money 01/14/26 | Audio Only\n",
      "  Preview: Hey, I'm Kramer. Welcome to Mad Money. Welcome to Crra America, my friends. Hey, I'm just trying to make a little bit of money here. My job is not jus...\n",
      "\n",
      "[2/100] Fetching: wN2s5uGh1YQ (waiting 7.0s)...\n",
      "âœ“ Success: Lightning Round: MNTN stock is 'just awful', says \n",
      "  Preview: THAT TIME. I STEPPED UP TO THE PLATE AND SAM. AND THEN THE LIGHTNING ROUND IS OVER. ARE YOU READY FOR THE LIGHTNING ROUND? WE'RE GOING TO START WITH J...\n",
      "\n",
      "[3/100] Fetching: 13vajHlMZQs (waiting 6.4s)...\n",
      "âœ“ Success: Jim Cramer shares his take on banking stocks\n",
      "  Preview: And just the last two sessions, J.P. Morgan's stock is down more than 5%. Bank of America is off almost 6%. Citigroup shed over 4%. And Wells Fargo ha...\n",
      "\n",
      "[4/100] Fetching: ZeXPc1jcYqk (waiting 6.1s)...\n",
      "âœ“ Success: The market is developing a thesis that is the oppo\n",
      "  Preview: Money. Welcome to Cramer friends. Hey I'm just trying to make a little bit of money here. My job is not just to entertain but to explain. So Has to be...\n",
      "\n",
      "[5/100] Fetching: qaHiso5XtI8 (waiting 6.2s)...\n",
      "Attempt 1 failed for qaHiso5XtI8: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=qaHiso5XtI8! This is \n",
      "âœ“ Success: Bank earnings numbers were actually good, says Jim\n",
      "  Preview: In the past two days, we've gotten results from all the big national banks, JP Morgan, Wells Fargo, Bank of America, and City Group. And I got to tell...\n",
      "\n",
      "[6/100] Fetching: N4GdJtz4m0w (waiting 7.1s)...\n",
      "âœ“ Success: The wrong stocks are going higher and I think that\n",
      "  Preview: You never want to see what's happening right now in the stock market. You see, the market's developing a thesis, and it's not the thesis you and I wer...\n",
      "\n",
      "[7/100] Fetching: GOa3SfkQ0vE (waiting 6.8s)...\n",
      "Attempt 1 failed for GOa3SfkQ0vE: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=GOa3SfkQ0vE! This is \n",
      "Attempt 2 failed for GOa3SfkQ0vE: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=GOa3SfkQ0vE! This is \n",
      "Attempt 3 failed for GOa3SfkQ0vE: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=GOa3SfkQ0vE! This is \n",
      "âœ— Failed/No transcript: LIVE: Replit CEO on vibe-coded apps launch, Claude\n",
      "\n",
      "[8/100] Fetching: 8bEoXYe75qc (waiting 6.4s)...\n",
      "Attempt 1 failed for 8bEoXYe75qc: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=8bEoXYe75qc! This is \n",
      "âœ“ Success: Final Trade: EL, RIG, XOM, C\n",
      "  Preview: TIM. >> THE HUMOR TONIGHT WAS REALLY A LITTLE OFF COLOR, BUT IF YOU NEED TO POWDER UP, GO TO ESTEE LAUDER. >> KAREN. >> YES, CITIBANK DOWN OVER $10 IN...\n",
      "\n",
      "[9/100] Fetching: OKMktKn12dI (waiting 6.8s)...\n",
      "âœ“ Success: 'Fast Money' traders Julie Biel and Courtney Garci\n",
      "  Preview: IT IS DAY THREE OF UNVEILING OUR 2026 TRADER ACRONYMS. TODAY WE HAVE GOT JULIE BEALE WITH HER PICKS. NOW LAST YEAR'S JULIE'S MOCHA ACRONYM CONSISTED O...\n",
      "\n",
      "[10/100] Fetching: QbUnGXh8sxE (waiting 6.3s)...\n",
      "âœ“ Success: Peachtree CEO Greg Friedman talks outlook for Comm\n",
      "  Preview: WITH THE CEO OF STRUCTURED THERAPEUTICS, RAY STEVENS, ON THE BACK OF POSITIVE PHASE TWO DATA OF THE COMPANY'S ORAL WEIGHT LOSS DRUG THAT IS TOMORROW R...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 10 videos\n",
      "\n",
      "[11/100] Fetching: r6zERzzLwdY (waiting 7.4s)...\n",
      "âœ“ Success: Software stocks will rebound from AI scare, says D\n",
      "  Preview: SURGING AND EXXON SURGING, THERE'S A MESSAGE FOR THE MARKET. >> ALL RIGHT CARTER GREAT TO SEE YOU. THANK YOU CARTER BRAXTON WORTH OF WORTH CHARTING. N...\n",
      "\n",
      "[12/100] Fetching: M0C35pWRHaE (waiting 7.5s)...\n",
      "âœ“ Success: Chart Master: Time to trim tech positions\n",
      "  Preview: MILLION TO 300,000,000OZ PER YEAR ON A DEFICIT. SO THERE'S A REAL SUPPLY DEMAND ISSUE WITH SILVER. YOU DON'T GET THAT WITH GOLD. >> LET'S GET TO TECH ...\n",
      "\n",
      "[13/100] Fetching: ICma1KRRYkk (waiting 7.3s)...\n",
      "âœ“ Success: 'Fast Money' traders talk swings in the oil market\n",
      "  Preview: UNREST INTERNALLY, THAT COULD ALSO JUST IMPACT OPERATIONS. IF PROTESTERS WERE TO TARGET ANY TYPE OF OIL INFRASTRUCTURE. >> YEAH. GREAT POINTS. PIPPA. ...\n",
      "\n",
      "[14/100] Fetching: w_arX9-YzSs (waiting 7.8s)...\n",
      "âœ“ Success: Fmr. Dallas Fed President: New Fed Chair will stil\n",
      "  Preview: DEAL WITH THE OTHER BIG ISSUES OF THE DAY, WHICH THIS IS DETRACTING FROM, THIS WOULD BE, IN MY VIEW, AN ELEGANT WAY OUT OF IT. >> ALL RIGHT. FOR MORE ...\n",
      "\n",
      "[15/100] Fetching: JOaBE-2gMQk (waiting 6.3s)...\n",
      "âœ“ Success: Greenland important for Arctic security, doesn't n\n",
      "  Preview: THE LAST WEEK OR SO KILLING OF LIKELY CIVILIANS. EAMON JAVERS, THANK YOU VERY MUCH. FOR MORE ON ALL OF THIS, LET'S BRING IN COUNCIL ON FOREIGN RELATIO...\n",
      "\n",
      "[16/100] Fetching: k_PuZlMtySY (waiting 7.0s)...\n",
      "âœ“ Success: Ariel's Charles Bobrinskoy: Oil is poised to move \n",
      "  Preview: >> ALL RIGHT 4.14 RICK SANTELLI. THANK YOU. ALL RIGHT THAT DOWN. LET'S GET MORE NOW ON THE MARKETS AND YOUR MONEY. AND ALSO MAYBE SOME BIG MONEY OPPOR...\n",
      "\n",
      "[17/100] Fetching: edhgyaqbQjs (waiting 6.5s)...\n",
      "âœ“ Success: OpenAI strikes $10 billion chip deal with Cerebras\n",
      "  Preview: HERE. >> ALL RIGHT JASON I APPRECIATE IT. THANKS VERY MUCH. TALK TO YOU AGAIN SOON. WE ARE GETTING SOME NEWS ON OPENAI. LET'S GET TO KATE ROONEY FOR T...\n",
      "\n",
      "[18/100] Fetching: rwvRIf_P7iw (waiting 6.6s)...\n",
      "Attempt 1 failed for rwvRIf_P7iw: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=rwvRIf_P7iw! This is \n",
      "âœ“ Success: Markets more about getting rotations right this ye\n",
      "  Preview: CURRENT LEVELS, WE COULD START TO SEE SOME INDUSTRIAL DEMAND DESTRUCTION. MIKE. >> ALL RIGHT. THANK YOU SO MUCH, JOHN. CLOVIS, YOU'VE BEEN HERE WAITIN...\n",
      "\n",
      "[19/100] Fetching: -njJd-i5Fn4 (waiting 6.7s)...\n",
      "âœ“ Success: Huge demand for large stage tech companies, says H\n",
      "  Preview: THE YEAR OF THE LARGEST TECH IPOS EVER? ALL EYES ARE ON SPACEX, OPENAI, AND ANTHROPIC AS THEY GEAR UP TO MAKE THEIR POTENTIAL TRILLION DOLLAR DEBUTS. ...\n",
      "\n",
      "[20/100] Fetching: FKRttG6o0rQ (waiting 7.5s)...\n",
      "âœ“ Success: Big banks had strong earnings but high expectation\n",
      "  Preview: MENTIONED ON THE CALL THAT IT EXPECTS TO CONTINUE REDUCING HEADCOUNT AND AUTOMATE MORE PROCESSES. >> MIKE LESLIE, THANK YOU VERY MUCH. LET'S BRING IN ...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 20 videos\n",
      "\n",
      "[21/100] Fetching: XbqhCO7qbu4 (waiting 7.8s)...\n",
      "âœ“ Success: Coinbase weighs in on latest crypto market structu\n",
      "  Preview: Today, digital currencies are on the rise as Bitcoin crosses the $97,000 mark for the first time since November. Pakistan enters a crypto payments dea...\n",
      "\n",
      "[22/100] Fetching: Mq6Xl8FjbCA (waiting 6.6s)...\n",
      "âœ“ Success: President Trump signs executive actions in the Ova\n",
      "  Preview: Okay. Hello everybody. >> Thank you very much. >> You see that beautiful milk? That's what we're >> here for. We're going to be discussing milk and wh...\n",
      "\n",
      "[23/100] Fetching: CtKdHqG48k8 (waiting 7.4s)...\n",
      "âœ“ Success: OBBB taxes and deregulation are the big drivers of\n",
      "  Preview: SUCH AS CONSUMER STAPLES AND ENERGY, THEY'RE BENEFITING FROM THIS RELENTLESS ROTATION THAT HAS SO FAR BEEN THE PREVAILING TONE IN 2026, WHICH TAKES US...\n",
      "\n",
      "[24/100] Fetching: EnyZvESHRKg (waiting 6.8s)...\n",
      "âœ“ Success: Charlotte Mayor: All about making sure community a\n",
      "  Preview: 35 OTHER CITY AND METRO AREA INDEXES. OH, NORTH CAROLINA ALSO WON CNBC'S TOP STATE NUMBER ONE FOR BUSINESS LAST YEAR. SO LET'S TALK MORE ABOUT THE BUS...\n",
      "\n",
      "[25/100] Fetching: _UzNBQcDSD4 (waiting 8.0s)...\n",
      "âœ“ Success: Danish official: Not respecting Greenland's right \n",
      "  Preview: The president has made his view clear and we have a different position. We, the Kingdom of Denmark, continue to believe that also the long-term securi...\n",
      "\n",
      "[26/100] Fetching: 2c80e9RSOUE (waiting 7.9s)...\n",
      "âœ“ Success: Bank of America CEO: Consumers are spending and sm\n",
      "  Preview: TOPPED EARNINGS EXPECTATIONS, I SHOULD SAY, ON BOTH EARNINGS AND REVENUE, AND POSTED NEARLY 10% YEAR ON YEAR GROWTH IN NET INTEREST INCOME, A KEY METR...\n",
      "\n",
      "[27/100] Fetching: e7M7RGB6JgY (waiting 6.6s)...\n",
      "âœ“ Success: Silver is a big momentum trade, says Jefferies' Da\n",
      "  Preview: TODAY AND SILVER NOW ABOVE $90 AN OUNCE. IT WAS $30 AN OUNCE ONE YEAR AGO. DOES ANY OF THIS SARAT IN THAT BIG BRAIN OF YOURS, DOES ANY OF THIS SOUND L...\n",
      "\n",
      "[28/100] Fetching: 5WTAGv5cV6Y (waiting 7.5s)...\n",
      "Attempt 1 failed for 5WTAGv5cV6Y: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=5WTAGv5cV6Y! This is \n",
      "âœ“ Success: Fed's beige book shows economic activity increased\n",
      "  Preview: >> GOING AND I. >> THINK THEY'RE GOING TO GET. >> BOTH A UNICORN RIDING A PONY ON MY YACHT. >> THEY WANT BOTH BEFORE NOVEMBER, GUYS. >> THANKS, DAVE. ...\n",
      "\n",
      "[29/100] Fetching: RJSpoB1vM9o (waiting 7.4s)...\n",
      "âœ“ Success: Chinese AI models adapt without Nvidia\n",
      "  Preview: CHINA MAY SHOW THE COUNTRY DOESN'T NEED THE CHIP MAKER OR IS TRYING NOT TO NEED THEM. ANYWAY, LET'S GET OVER TO DEIRDRE BOSA FOR MORE ON TODAY'S TECH ...\n",
      "\n",
      "[30/100] Fetching: kEzwvU7-J8Q (waiting 8.0s)...\n",
      "âœ“ Success: Elon Musk's xAI probed by California DOJ over Grok\n",
      "  Preview: The California state's attorney general is opening an investigation into Elon Musk's AI company XAI the AG here Rob Bont saying in a statement the cha...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 30 videos\n",
      "\n",
      "[31/100] Fetching: dvMiDN3f0NA (waiting 6.2s)...\n",
      "âœ“ Success: Good time to be in the real estate marketplace, sa\n",
      "  Preview: WITH A 6% OR PLUS MORTGAGE THAN WITH THOSE BELOW A 3% RATE. SO COULD ALL OF THIS START UNLOCKING INVENTORIES AHEAD OF THE SPRIN...\n",
      "\n",
      "[32/100] Fetching: dWT6EgLWOac (waiting 7.4s)...\n",
      "âœ“ Success: Denmark and Greenland officials meeting with VP Va\n",
      "  Preview: SECRETARY OF STATE RUBIO ARE MEETING WITH OFFICIALS FROM DENMARK AND GREENLAND AT THE WHITE HOUSE TODAY. LET'S BRING IN EAMON JAVERS WITH THE LATEST D...\n",
      "\n",
      "[33/100] Fetching: 6AUM9gxMEw8 (waiting 6.9s)...\n",
      "âœ“ Success: Sen. Warren says Trump called her to work on credi\n",
      "  Preview: you get a call from the president. Were you surprised? What happened? >> Yes, I was surprised. In fact, I did not recognize the phone number. Uh and u...\n",
      "\n",
      "[34/100] Fetching: 1U2o10yAp8A (waiting 6.3s)...\n",
      "âœ“ Success: Officials from Denmark and Greenland hold news con\n",
      "  Preview: if possible further in-depth work to deliver on them. On this basis, we had what I will describe as a frank but also constructive discussion. The disc...\n",
      "\n",
      "[35/100] Fetching: x5uixRdjxRA (waiting 7.6s)...\n",
      "âœ“ Success: Squawk Pod: Sen. Warren on a credit card rate cap \n",
      "  Preview: Bring in show music, please. >> Hi, I'm CNBC producer Katie Kramer. Today on Squawk Pod, >> I [music] don't believe in caps. I believe in free markets...\n",
      "\n",
      "[36/100] Fetching: JzOKzWG5sMg (waiting 6.6s)...\n",
      "âœ“ Success: 'Pretty weak' case for Fed rate cuts in the near-t\n",
      "  Preview: OUR NEXT GUEST DOESN'T SEE ANY RATE CUTS THIS YEAR AND IN FACT THINKS THE FED'S NEXT MOVE WILL BE A RATE HIKE IN 2027. JOINING US NOW IS MICHAEL FEROL...\n",
      "\n",
      "[37/100] Fetching: HeLw0aEvqoI (waiting 7.0s)...\n",
      "Attempt 1 failed for HeLw0aEvqoI: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=HeLw0aEvqoI! This is \n",
      "âœ“ Success: Crude oil rally has more room to run, says Citi's \n",
      "  Preview: CLOSES WITH MEGA MAKE IRAN GREAT AGAIN. MY NEXT GUEST SAYING BRANT COULD HIT 70 BUCKS IN THE NEXT THREE MONTHS AS WE WORK THROUGH ALL THIS. JOINING US...\n",
      "\n",
      "[38/100] Fetching: qM1Oy_d7Tzw (waiting 6.3s)...\n",
      "âœ“ Success: Current productivity uptrend can last for some tim\n",
      "  Preview: LOWER FOR A SECOND STRAIGHT DAY AS INVESTORS WEIGH THE LATEST ECONOMIC DATA, PLUS THE BANK EARNINGS PLUS THE POLITICAL HEADLINES. THE NASDAQ IS SEEING...\n",
      "\n",
      "[39/100] Fetching: OPP99_5mpVM (waiting 7.2s)...\n",
      "âœ“ Success: California Attorney General launches investigation\n",
      "  Preview: LAFFER TENGLER INVESTMENTS. DON'T MISS THE BIG INTERVIEW TOMORROW MORNING WITH BLACKROCK CHAIR AND CEO LARRY FINK. HE WILL BE ON SQUAWK ON THE STREET ...\n",
      "\n",
      "[40/100] Fetching: lCFyyUettNo (waiting 6.0s)...\n",
      "âœ“ Success: House holds hearing on oversight of the Federal Co\n",
      "  Preview: remains viable for future generations. Today's hearing is an opportunity to discuss the many important issues before the FCC. Again, I thank the commi...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 40 videos\n",
      "\n",
      "[41/100] Fetching: 3vC0hWJJq1A (waiting 7.8s)...\n",
      "âœ“ Success: House GOP's stock trading ban bill clears key hurd\n",
      "  Preview: So, a key house panel just approved a bill that would ban lawmakers from being able to buy stocks. And this has been a huge debate on Capitol Hill. Th...\n",
      "\n",
      "[42/100] Fetching: idaubGNM7KI (waiting 6.8s)...\n",
      "Attempt 1 failed for idaubGNM7KI: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=idaubGNM7KI! This is \n",
      "âœ“ Success: Investment Committee: Here's how to navigate the m\n",
      "  Preview: COMING OVER TO YOU JOE. TO START THINGS OFF IT'S HARD TO ANSWER THAT QUESTION JUST BASED ON ONE DAY. WE DID HAVE THE MARKETS HIT A RECORD HIGH JUST EA...\n",
      "\n",
      "[43/100] Fetching: 2q7mIvNhEtc (waiting 6.0s)...\n",
      "âœ“ Success: Chart of the Day: Oil's big bounce\n",
      "  Preview: LET'S HIT OUR CHART OF THE DAY. IT'S OIL REBOUNDING OVER THE PAST WEEK. ON RISING TENSIONS IN IRAN AND VENEZUELA UP MORE THAN 10% TODAY UP OVER 1% JOE...\n",
      "\n",
      "[44/100] Fetching: YI9t557Qe4U (waiting 7.9s)...\n",
      "Attempt 1 failed for YI9t557Qe4U: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=YI9t557Qe4U! This is \n",
      "Attempt 2 failed for YI9t557Qe4U: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=YI9t557Qe4U! This is \n",
      "Attempt 3 failed for YI9t557Qe4U: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=YI9t557Qe4U! This is \n",
      "âœ— Failed/No transcript: Trade Tracker: Karen Firestone buys Linde PLC\n",
      "\n",
      "[45/100] Fetching: UHDWOXEF7s0 (waiting 7.2s)...\n",
      "âœ“ Success: Final Trades: GLD, CNX, RJF and the IYM\n",
      "  Preview: MARKETS AT SESSION LOWS. YOU SEE THE DOW DOWN ABOUT A HALF A PERCENT RIGHT NOW. IT'S ALSO TIME FOR FINAL TRADES STEVE WEISS, YOU'RE UP FIRST. >> BOSSI...\n",
      "\n",
      "[46/100] Fetching: eR0QRl4iEHo (waiting 6.4s)...\n",
      "âœ“ Success: Software stocks are facing competition from AI\n",
      "  Preview: In the last 48 hours, there's been two major announcements that have really rocked software stocks. First, Anthropics Cloud unveiling an AI agent that...\n",
      "\n",
      "[47/100] Fetching: E_G7zOHTed0 (waiting 7.9s)...\n",
      "Attempt 1 failed for E_G7zOHTed0: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=E_G7zOHTed0! This is \n",
      "âœ“ Success: AI challenging software incumbents\n",
      "  Preview: 2025 I THINK SHOULD CONTINUE TO WORK. >> YOU KNOW, WE'RE TALKING A LOT ABOUT THIS TWO MONTH PERIOD. THE MARKET CLOSE TO FLAT. BUT TECH ITSELF, IT'S AC...\n",
      "\n",
      "[48/100] Fetching: eXB44uITJP8 (waiting 7.1s)...\n",
      "âœ“ Success: Why investors are brushing off D.C. chaos\n",
      "  Preview: There's been a wave of political turmoil recently. The DOJ is pursuing a criminal investigation into Federal Reserve Chair Jerome Powell. There's the ...\n",
      "\n",
      "[49/100] Fetching: RlVlH-Xn6cE (waiting 6.6s)...\n",
      "Attempt 1 failed for RlVlH-Xn6cE: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=RlVlH-Xn6cE! This is \n",
      "Attempt 2 failed for RlVlH-Xn6cE: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=RlVlH-Xn6cE! This is \n",
      "Attempt 3 failed for RlVlH-Xn6cE: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=RlVlH-Xn6cE! This is \n",
      "âœ— Failed/No transcript: Wells Fargo CFO Michael Santomassimo on Q4 earning\n",
      "\n",
      "[50/100] Fetching: K2FXxRqenn8 (waiting 6.6s)...\n",
      "Attempt 1 failed for K2FXxRqenn8: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=K2FXxRqenn8! This is \n",
      "Attempt 2 failed for K2FXxRqenn8: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=K2FXxRqenn8! This is \n",
      "Attempt 3 failed for K2FXxRqenn8: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=K2FXxRqenn8! This is \n",
      "âœ— Failed/No transcript: Why the Supreme Court is taking longer to issue a \n",
      "\n",
      "  ðŸ’¾ Cache saved at 50 videos\n",
      "\n",
      "[51/100] Fetching: wNAssqaNh4o (waiting 7.4s)...\n",
      "âœ“ Success: House committee holds a hearing on advancing Ameri\n",
      "  Preview: The subcommittee on research and technology will come to order. Without objection, the chair is authorized to declare recesses of the subcommittee at ...\n",
      "\n",
      "[52/100] Fetching: XiO3183wtu8 (waiting 6.6s)...\n",
      "Attempt 1 failed for XiO3183wtu8: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=XiO3183wtu8! This is \n",
      "Attempt 2 failed for XiO3183wtu8: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=XiO3183wtu8! This is \n",
      "Attempt 3 failed for XiO3183wtu8: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=XiO3183wtu8! This is \n",
      "âœ— Failed/No transcript: Fed Chair Powell stepping down would be 'an elegan\n",
      "\n",
      "[53/100] Fetching: _fVHNG1DcX0 (waiting 7.8s)...\n",
      "Attempt 1 failed for _fVHNG1DcX0: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=_fVHNG1DcX0! This is \n",
      "Attempt 2 failed for _fVHNG1DcX0: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=_fVHNG1DcX0! This is \n",
      "Attempt 3 failed for _fVHNG1DcX0: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=_fVHNG1DcX0! This is \n",
      "âœ— Failed/No transcript: Banks and financials could benefit from the produc\n",
      "\n",
      "[54/100] Fetching: g4Yea1WFZEM (waiting 6.7s)...\n",
      "âœ“ Success: U.S. greenlights Nvidia H200 sales\n",
      "  Preview: INSURANCE. >> NVIDIA TODAY CLEARING THE LAST U.S. GOVERNMENT HURDLE TO EXPORT THOSE H-2 HUNDREDS TO CHINA, BUT HAS THE CHIP MAKERS MOMENT THEY'RE ALRE...\n",
      "\n",
      "[55/100] Fetching: i_IIS-CrCIw (waiting 7.2s)...\n",
      "Attempt 1 failed for i_IIS-CrCIw: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=i_IIS-CrCIw! This is \n",
      "Attempt 2 failed for i_IIS-CrCIw: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=i_IIS-CrCIw! This is \n",
      "Attempt 3 failed for i_IIS-CrCIw: VideoUnplayable: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=i_IIS-CrCIw! This is \n",
      "âœ— Failed/No transcript: Mixed quarter as big banks begin earnings season\n",
      "\n",
      "[56/100] Fetching: BvsyJm261Mw (waiting 6.9s)...\n",
      "Attempt 1 failed for BvsyJm261Mw: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=BvsyJm261Mw! This is \n",
      "âœ“ Success: How Saks ran itself into bankruptcy\n",
      "  Preview: bankruptcy. But that's not because the luxury consumer isn't spending. Saks' problems have been a long time in the making, and a lot of it was their o...\n",
      "\n",
      "[57/100] Fetching: We1b4zCeke4 (waiting 6.9s)...\n",
      "âœ“ Success: Elon Musk says Tesla is moving Full Self-Driving t\n",
      "  Preview: for some time when Tesla has offered its full self-driving software to uh buyers of its vehicles. You could either do it as a one-time payment when yo...\n",
      "\n",
      "[58/100] Fetching: JWpB1wmqA6k (waiting 6.9s)...\n",
      "âœ“ Success: Tesla takes Full Self-Driving feature to a monthly\n",
      "  Preview: well and live well. And right now, you can level >> COM TESLA MAKING A BIG CHANGE AROUND HOW IT SELLS CUSTOMERS ITS FULL SELF-DRIVING SERVICE. PHIL LE...\n",
      "\n",
      "[59/100] Fetching: 2QgtlRIGBFA (waiting 6.8s)...\n",
      "Attempt 1 failed for 2QgtlRIGBFA: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=2QgtlRIGBFA! This is \n",
      "âœ“ Success: The current tariff environment is not nearly as un\n",
      "  Preview: DOES GET TO THE FLOOR, THERE IS GOING TO BE A LOT OF POLITICAL PRESSURE TO VOTE. YES. >> OKAY, EMILY, KEEP US POSTED ON THAT. EMILY WILKINS ON CAPITOL...\n",
      "\n",
      "[60/100] Fetching: fTWMFQ8i-1Y (waiting 6.7s)...\n",
      "âœ“ Success: Why Trump's Actions Don't Seem To Move The Market \n",
      "  Preview: There's been a wave of \n",
      "political turmoil recently. The DOJ is pursuing a \n",
      "criminal investigation into Federal Reserve Chair Jerome \n",
      "Powell. There's t...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 60 videos\n",
      "\n",
      "[61/100] Fetching: -L_UPQGN6MQ (waiting 6.6s)...\n",
      "âœ“ Success: Congressional stock trading ban bill to get its fi\n",
      "  Preview: Colors and co presence starts here. >> COM CONGRESS KICKING OFF AN INITIAL VOTE THIS HOUR TO POTENTIALLY BAN STOCK TRADING BY LAWMAKERS. OUR EMILY WIL...\n",
      "\n",
      "[62/100] Fetching: irxJdnDV34Y (waiting 6.6s)...\n",
      "Attempt 1 failed for irxJdnDV34Y: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=irxJdnDV34Y! This is \n",
      "âœ“ Success: Scaled-back Congressional stock trading ban bill g\n",
      "  Preview: Look, lawmakers would no longer be able to buy new stocks while they're in office under this bill that is being debated right now. But critics are alr...\n",
      "\n",
      "[63/100] Fetching: nx9qOf60T4o (waiting 6.7s)...\n",
      "âœ“ Success: 'We're pleased' with Warner Bros. bidding war, say\n",
      "  Preview: FROM NETFLIX, BECOME A LOT SHORTER, WHICH IS GOOD NEWS, ISN'T IT? FOR ALL OF US. WON'T HAVE TO HEAR ME TALKING ABOUT THIS ENDLESSLY. BUT SPEAKING OF W...\n",
      "\n",
      "[64/100] Fetching: FN5ps270IDo (waiting 7.6s)...\n",
      "âœ“ Success: It's a 'good time for the Fed to pause' cutting in\n",
      "  Preview: MANY OF THOSE TARIFFS THAT THEY PUT ON ON THE US. SO I DON'T I DON'T ANTICIPATE THERE'LL BE A BIG CHANGE. >> WHAT DO YOU THINK. WHAT'S YOUR THINKING A...\n",
      "\n",
      "[65/100] Fetching: 8JEt4Ih_SSs (waiting 6.5s)...\n",
      "âœ“ Success: Supreme Court will not issue decision on tariffs t\n",
      "  Preview: VERY MUCH. IMPORTANT TOPIC ON A BUSY DAY. WE'LL TALK SOON. >> ALL RIGHT. TAKE CARE. >> LORETTA MESTER. LET'S CHECK IN WITH EAMON JAVERS ON THIS SCOTUS...\n",
      "\n",
      "[66/100] Fetching: l2wP5BRKWPI (waiting 7.7s)...\n",
      "Attempt 1 failed for l2wP5BRKWPI: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=l2wP5BRKWPI! This is \n",
      "âœ“ Success: Existing home sales end 2025 with a strong beat, a\n",
      "  Preview: THIS IS EXCITING STUFF. THIS IS LIVE TV BREAKING NEWS WITHOUT A SAFETY NET. AND WE'LL SEE WHAT WE GET. >> ALL RIGHT EAMON, WE WILL GET BACK TO YOU AS ...\n",
      "\n",
      "[67/100] Fetching: G52isrO1S5g (waiting 6.3s)...\n",
      "âœ“ Success: Philadelphia Fed President Paulson: Fed funds rate\n",
      "  Preview: HEADLINES HERE FROM ONE OF THE FED VOTERS THIS YEAR. THIS IS THE PRESIDENT OF THE PHILADELPHIA FED, ANNA PAULSON, WHO IS SPEAKING IN PHILADELPHIA. JUS...\n",
      "\n",
      "[68/100] Fetching: oci1PaBQEu4 (waiting 6.1s)...\n",
      "âœ“ Success: Airbnb CEO on new CTO: We have an opportunity to d\n",
      "  Preview: We have a unique philosophy at Airbnb. I think a lot people in Silicon Valley start with the technology and they try to find uses for the technology. ...\n",
      "\n",
      "[69/100] Fetching: m7b2ccri5bw (waiting 6.2s)...\n",
      "âœ“ Success: Opening Bell: January 14, 2026\n",
      "  Preview: EVERYTHING ELSE THROUGH ROTATION. SO WE CAME INTO THE YEAR. EVERYBODY IS POSITIONED FOR CYCLICALS TO DO WELL FOR THE ECONOMY TO RE-ACCELERATE FOR EARN...\n",
      "\n",
      "[70/100] Fetching: 02WhsM3EeSU (waiting 6.1s)...\n",
      "âœ“ Success: Bank of America tops estimates on better-than-expe\n",
      "  Preview: Bank of America shares, they're up about 1% on these fourth quarter results. Bank of America beating on the bottom line for the fourth quarter by abou...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 70 videos\n",
      "\n",
      "[71/100] Fetching: _cqSIiBpO30 (waiting 6.3s)...\n",
      "âœ“ Success: Faber Report: Netflix likely to make Warner Bros. \n",
      "  Preview: INSURANCE. >> WELCOME BACK SOME NEW DEVELOPMENTS ON THE BATTLE FOR WARNER BROTHERS DISCOVERY LATE YESTERDAY, SOME REPORTING FROM FROM COMPETITORS THAT...\n",
      "\n",
      "[72/100] Fetching: 1C4WyKqbAc0 (waiting 7.0s)...\n",
      "âœ“ Success: White House, markets await tariff decision: Here's\n",
      "  Preview: DIFFERENT PLACES THEY'RE GOING TO BE USING IT. >> YEAH. CITY SHARES WERE LOWER PREMARKET ACTUALLY HAVE REVERSED INTO THE GREEN. WE'LL GET TO B OF A IN...\n",
      "\n",
      "[73/100] Fetching: -3ilydpD9Do (waiting 6.1s)...\n",
      "âœ“ Success: Sen. Warren on Trump phone call, credit card rate \n",
      "  Preview: EVERYBODY. PRESIDENT TRUMP REACHED OUT TO DEMOCRATIC SENATOR ELIZABETH WARREN FOR A CONVERSATION THAT THE WHITE HOUSE CALLED PRODUCTIVE. JOINING US RI...\n",
      "\n",
      "[74/100] Fetching: ntXAPYwKZ5s (waiting 7.2s)...\n",
      "âœ“ Success: Citigroup tops estimates as loan loss provisions c\n",
      "  Preview: city's fourth quarter results impacted though by the sale of its remaining operations in Russia. So that resulted in an impact to EPS of about 62 cent...\n",
      "\n",
      "[75/100] Fetching: zaAGe4JfLOw (waiting 6.7s)...\n",
      "âœ“ Success: Roger Ferguson: The Fed and the market are now ali\n",
      "  Preview: WELL OUTSIDE THE REALM OF EXPECTATIONS. SO MOST LIKELY THERE IS SOME SMOKE WHERE THERE IS FIRE. >> OKAY. THANKS RICK. JOINING US NOW. THANK YOU. ROGER...\n",
      "\n",
      "[76/100] Fetching: 8HnBiXcJIkc (waiting 6.9s)...\n",
      "âœ“ Success: November PPI 0.2% vs. 0.3% estimate\n",
      "  Preview: X AUTOS AND GAS NUMBER OVER HALF OF 1%. I THINK THOSE ARE THE TWO METRICS I'M PAYING CLOSEST ATTENTION TO. AND HERE WE GO GETTING VERY CLOSE TO THE RE...\n",
      "\n",
      "[77/100] Fetching: pEbBsaaH6ds (waiting 7.6s)...\n",
      "âœ“ Success: Airbnb CEO Brian Chesky on new CTO: We have an opp\n",
      "  Preview: What am I? >> WELCOME BACK TO SQUAWK BOX NEW THIS MORNING AIRBNB ANNOUNCING IT HAS NOW HIRED A NEW CHIEF TECHNOLOGY OFFICER. AHMED ABDULLAH IS JOINING...\n",
      "\n",
      "[78/100] Fetching: i3cUUHQhivM (waiting 6.3s)...\n",
      "âœ“ Success: Citigroup tops estimates as loan loss provisions c\n",
      "  Preview: THAT WE SUPPORT. >> OKAY. THANK YOU VERY MUCH FOR BEING WITH US. AMBASSADOR MALONEY. WE APPRECIATE IT. >> MY PLEASURE. >> MEANTIME, CITY JUST OUT WITH...\n",
      "\n",
      "[79/100] Fetching: 1U5QvPREQK0 (waiting 7.9s)...\n",
      "âœ“ Success: Coalition for Prediction Markets CEO: We believe p\n",
      "  Preview: LIKE ROBINHOOD AND CRYPTO.COM HAVE FORMED A NEW COALITION. ITS FOCUS IS TO ENSURE THAT FEDERAL LAW, NOT A PATCHWORK OF STATE REGULATIONS, WILL GOVERN ...\n",
      "\n",
      "[80/100] Fetching: hkgw73j25Ew (waiting 7.4s)...\n",
      "âœ“ Success: Rep. Hill on Powell probe: High construction costs\n",
      "  Preview: ANOTHER SWIPE AT FED CHAIR JAY POWELL CALLING HIM INCOMPETENT AND CROOKED. JOINING US NOW CONGRESSMAN FRENCH HILL IS THE CHAIRMAN OF THE FINANCIAL SER...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 80 videos\n",
      "\n",
      "[81/100] Fetching: 652twGE1lhg (waiting 6.7s)...\n",
      "âœ“ Success: Amos Hochstein on Iran protests: Just taking one p\n",
      "  Preview: indoor outdoor living. The decks. You've made it even better. I >> WELCOME BACK TO SQUAWK BOX PRESIDENT TRUMP TAKING TO SOCIAL MEDIA TO ONCE AGAIN WAR...\n",
      "\n",
      "[82/100] Fetching: IX9lORppIfQ (waiting 8.0s)...\n",
      "âœ“ Success: Buffett's philanthropic challenge: Here's what to \n",
      "  Preview: DEGREES AT THE THEN SOVIET VOSTOK STATION IN ANTARCTICA IN 1983. >> WARREN BUFFETT'S THREE CHILDREN ARE FACING ONE OF THE TOUGHEST AND MOST IMPORTANT ...\n",
      "\n",
      "[83/100] Fetching: pLylfyHpSLA (waiting 7.3s)...\n",
      "âœ“ Success: Bank earnings kickoff: Hightower's Stephanie Link \n",
      "  Preview: WEEK WHEN WE SEE THAT MORTGAGE RATES HAVE MOVED BACK OVER 6%, BUT THEY ARE STILL FAR LOWER THAN THEY WERE LAST YEAR. >> OKAY, DIANA. THANK YOU. WE'LL ...\n",
      "\n",
      "[84/100] Fetching: pQkR4l3DgzA (waiting 7.2s)...\n",
      "âœ“ Success: Mortgage refinance demand surges 40% higher after \n",
      "  Preview: THANKS, TOM. >> I GOT FAITH. DON'T WORRY JOE. >> YOU DO. YOU AND GEORGE MICHAEL. >> THERE YOU GO. ALL RIGHT. >> THAT WAS THAT WAS QUICK. ALL RIGHT. WE...\n",
      "\n",
      "[85/100] Fetching: _en5lGkivH0 (waiting 6.8s)...\n",
      "âœ“ Success: The solution to envy in our own lives is admiratio\n",
      "  Preview: CNBC Leaders playbook. Back to >> ARTHUR IS HERE TO WEIGH IN ON A BUSY START FOR 2026. LET'S BRING IN HARVARD PROFESSOR ARTHUR BROOKS. HE'S SO MUCH MO...\n",
      "\n",
      "[86/100] Fetching: w5Z6TB0IppQ (waiting 6.5s)...\n",
      "âœ“ Success: Bank of America tops estimates on better-than-expe\n",
      "  Preview: AND I CAN TELL YOU SHE'S. >> REALLY GOOD AT THIS SEASON. SHE'S SHE'S EXACTLY RIGHT. >> WE ADMIRE YOU, LESLIE. WE'RE SELF-ACTUALIZING. >> WOW. YOU'VE M...\n",
      "\n",
      "[87/100] Fetching: 6z7Oj1dsfIA (waiting 7.5s)...\n",
      "âœ“ Success: Wells Fargo misses Q4 revenue estimates\n",
      "  Preview: >> WELLS FARGO RELEASING QUARTERLY RESULTS JUST MOMENTS AGO. LESLIE PICKER JOINS US NOW WITH MORE. GOOD MORNING LESLIE. >> HEY GOOD MORNING JOE. YEAH....\n",
      "\n",
      "[88/100] Fetching: D3XyV0cazuU (waiting 6.6s)...\n",
      "âœ“ Success: Craig Buchholz: Reputation becomes measurable mark\n",
      "  Preview: at more than $7 trillion. For much more, let's bring in Craig Buchholz, us CEO at Burson. Craig, good morning. Great to have you on the show. >> Good ...\n",
      "\n",
      "[89/100] Fetching: dDFDFxFxnwY (waiting 7.7s)...\n",
      "âœ“ Success: Dave Mazza: AI leadership rotates beyond megacaps \n",
      "  Preview: Hill Investments. The firm holds Nvidia and a number of its ETFs, including the Magnificent Seven ETF and Chat Generative AI ETF. Dave, thanks so much...\n",
      "\n",
      "[90/100] Fetching: YKAirikMXTo (waiting 7.3s)...\n",
      "âœ“ Success: Populist turn raises new risks for Wall Street, sa\n",
      "  Preview: Pethokoukis, economic policy analyst at the American Enterprise Institute. He's also a CNBC contributor. Jimmy, good morning. Good to see you. >> Hey,...\n",
      "\n",
      "  ðŸ’¾ Cache saved at 90 videos\n",
      "\n",
      "[91/100] Fetching: AtGls7mz5bY (waiting 7.2s)...\n",
      "âœ“ Success: Akoner: This is the year of small caps and the ave\n",
      "  Preview: GOOD MORNING. THANK YOU FOR BEING HERE. I WANT TO HIT ON THAT DATA THAT JUST KIND OF CROSSED A SHORT TIME AGO. THE IDEA THAT CUSTOMERS FOR BANK OF AME...\n",
      "\n",
      "[92/100] Fetching: ljwErl6jsp0 (waiting 7.1s)...\n",
      "âœ“ Success: Fred Thiel: Bitcoin enters geopolitical era as min\n",
      "  Preview: publicly traded bitcoin miner behind strategy. He's a crypto and blockchain conference over in Switzerland. Fred good morning. Thank you for joining u...\n",
      "\n",
      "[93/100] Fetching: JG3uvOlCo50 (waiting 6.7s)...\n",
      "âœ“ Success: Giving away the Buffett fortune\n",
      "  Preview: The three of you um your father has told the world are going to be responsible for figuring out what to do with all the money that he has built up in ...\n",
      "\n",
      "[94/100] Fetching: 84RN9DX95bw (waiting 6.3s)...\n",
      "âœ“ Success: Netflix considers all-cash offer for Warner Bros. \n",
      "  Preview: CONSIDERING AN ALL CASH BID FOR THE STREAMING AND STUDIO ASSETS OF WARNER BROS. DISCOVERY REPORTS SAY A CASH OFFER COULD BE A FASTER WAY TO CLOSE THE ...\n",
      "\n",
      "[95/100] Fetching: WH4ZX16Qarg (waiting 7.1s)...\n",
      "âœ“ Success: 5 Things To Know: January 14, 2026\n",
      "  Preview: THESE BANK EARNINGS. SO THANK. >> YOU, THANK YOU. >> THANK YOU. AND WE WILL SEE YOU AGAIN IN JUST A LITTLE BIT. AGAIN, WELLS FARGO SHARES RIGHT NOW DO...\n",
      "\n",
      "[96/100] Fetching: cSLE0SIA_zM (waiting 7.1s)...\n",
      "âœ“ Success: The market doesn't believe we're losing Fed indepe\n",
      "  Preview: TAKE A LOOK AT FUTURES AT THIS HOUR. THE DOW OFF ABOUT 153 POINTS, THE NASDAQ DOWN ABOUT 164 POINTS. AND YOU'RE LOOKING AT THE S&P 500 OFF ABOUT 28 PO...\n",
      "\n",
      "[97/100] Fetching: 4krYixj0ioc (waiting 7.9s)...\n",
      "Attempt 1 failed for 4krYixj0ioc: RequestBlocked: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=4krYixj0ioc! This is \n",
      "âœ“ Success: Marsh CEO John Doyle on WEF Global Risks Report, c\n",
      "  Preview: The world is a risky place and becoming, it seems, increasingly so. Today we have a new report from Marsh talking about those global risks as well as ...\n",
      "\n",
      "[98/100] âœ“ Cached: OM9w1pyVOgc - Lightning Round: Hold on to Texas Instruments, say\n",
      "  Preview: LET'S TALK ABOUT I JUST GOT ANOTHER CALL ON MY PLAN THIS OUT AND THEN THE LIGHTNING ROUND IS OVER. ARE YOU READY, SKI DADDY? START WITH RON GALELLA. R...\n",
      "\n",
      "[99/100] âœ“ Cached: gtOCsnNUHiw - Amgen CEO Bob Bradway goes one-on-one with Jim Cra\n",
      "  Preview: AMGEN AMERITRADE. THEY'RE LATE STAGE ONCE A MONTH. GLP ONE WEIGHT LOSS INJECTION NOW. WALL STREET DIDN'T REACT TO THE NEWS, BUT THIS IS A BIG BIOTECH ...\n",
      "\n",
      "[100/100] âœ“ Cached: iXKXFyMt7Gg - Mad Money 01/13/26 | Audio Only\n",
      "  Preview: Hey, I'm Kramer. Welcome to a special West Coast edition of Bad Money. Welcome to Cray America from One Market in San Francisco. Other people make fri...\n",
      "\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "  âœ“ Successfully fetched: 90\n",
      "  âœ“ From cache: 3\n",
      "  âœ— Failed/No transcript: 7\n",
      "  Total processed: 100/100\n",
      "  ðŸ“¦ Final cache size: 100/100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "youtube_videos_api = attach_transcripts(youtube_videos_api, delay_between_requests = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a08c10",
   "metadata": {},
   "source": [
    "## Add transcripts to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6508b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrote 0 transcripts from cache\n"
     ]
    }
   ],
   "source": [
    "# Overwrite in-memory transcripts with cache values when available\n",
    "\n",
    "youtube_videos_api = refresh_transcripts_in_dict(youtube_videos_api)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d0e87",
   "metadata": {},
   "source": [
    "## Check rotating proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv(\"PROXY_USER\")\n",
    "password = os.getenv(\"PROXY_PASS\")\n",
    "endpoint = os.getenv(\"PROXY_HOST\") +  \":\" + str(os.getenv(\"PROXY_PORT\"))\n",
    "\n",
    "proxy_url = f\"http://{username}:{password}@{endpoint}\"\n",
    "\n",
    "def check_ip_rotation(num_requests=10):\n",
    "    \"\"\"Check if proxy IPs are rotating\"\"\"\n",
    "    proxies = {\n",
    "        'http': proxy_url,\n",
    "        'https': proxy_url\n",
    "    }\n",
    "    \n",
    "    ips = []\n",
    "    for i in range(num_requests):\n",
    "        try:\n",
    "            # Using http instead of https for simpler testing\n",
    "            response = requests.get('http://ipinfo.io/json', \n",
    "                                   proxies=proxies, \n",
    "                                   timeout=10)\n",
    "            ip = response.json().get('ip')\n",
    "            ips.append(ip)\n",
    "            print(f\"Request {i+1}: IP = {ip}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Request {i+1} failed: {e}\")\n",
    "    \n",
    "    unique_ips = set(ips)\n",
    "    print(f\"\\nTotal requests: {len(ips)}\")\n",
    "    print(f\"Unique IPs: {len(unique_ips)}\")\n",
    "    print(f\"IPs are {'ROTATING âœ“' if len(unique_ips) > 1 else 'NOT ROTATING âœ—'}\")\n",
    "    return ips\n",
    "\n",
    "# Test rotation\n",
    "print(\"Testing IP rotation with Webshare:\")\n",
    "check_ip_rotation(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff8479",
   "metadata": {},
   "source": [
    "# After Transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17316fe",
   "metadata": {},
   "source": [
    "## Sentiment and Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0007c875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing first video with debug output:\n",
      "\n",
      "Title: Mad Money 01/14/26 | Audio Only\n",
      "   Transcript length: 45338 chars, 8239 words\n",
      "   Word count: 8239\n",
      "    Truncated to 1000 words\n",
      "   Generating summary...\n",
      "   First 200 chars: Hey, I'm Kramer. Welcome to Mad Money. Welcome to Crra America, my friends. Hey, I'm just trying to make a little bit of money here. My job is not just to entertain, but to explain. So call me at 1800\n",
      "   Summary: In a good market, you want a broad rally led by growth stocks when the cyclical is taking a backseat but still going higher. Most of all, I like to see the bank stocks go higher. When the banks are winning, it tells you businesses are expanding. The only people who' qualify for credit cards are the ones who don't need the money.\n",
      "   Sentiment: {'label': 'neutral', 'score': 0.7668792009353638}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      " Analyzing all videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [18:32<00:00, 11.12s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "def chunk_text_words(text, chunk_words=500):\n",
    "    words = text.split()\n",
    "    return [\n",
    "        \" \".join(words[i:i+chunk_words])\n",
    "        for i in range(0, len(words), chunk_words)\n",
    "    ]\n",
    "\n",
    "def summarize_long_text(text):\n",
    "    chunks = chunk_text_words(text, chunk_words=500)\n",
    "\n",
    "    partial_summaries = []\n",
    "    for chunk in chunks:\n",
    "        result = summarizer(\n",
    "            chunk,\n",
    "            max_length=120,\n",
    "            min_length=40,\n",
    "            do_sample=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        partial_summaries.append(result[0][\"summary_text\"])\n",
    "\n",
    "    combined = \" \".join(partial_summaries)\n",
    "\n",
    "    final = summarizer(\n",
    "        combined,\n",
    "        max_length=180,\n",
    "        min_length=60,\n",
    "        do_sample=False,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    return final[0][\"summary_text\"]\n",
    "\n",
    "\n",
    "def analyze_video_sentiment(video, debug=False):\n",
    "    \"\"\"Analyze sentiment of title and transcript separately\"\"\"\n",
    "    \n",
    "    # Title: Direct sentiment (no summarization)\n",
    "    title = video.get('title', '')\n",
    "    if title:\n",
    "        try:\n",
    "            title_sentiment = sentiment_analyzer(title[:512])[0]\n",
    "            video['title_sentiment'] = title_sentiment\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"    Title sentiment failed: {e}\")\n",
    "            video['title_sentiment'] = None\n",
    "    else:\n",
    "        video['title_sentiment'] = None\n",
    "    \n",
    "    # Transcript: Summarize â†’ Sentiment\n",
    "    transcript_text = video.get('transcript_text', '')\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"   Transcript length: {len(transcript_text)} chars, {len(transcript_text.split())} words\")\n",
    "    \n",
    "    # Check if transcript exists and is long enough\n",
    "    if not transcript_text or len(transcript_text.strip()) < 200:\n",
    "        if debug:\n",
    "            print(f\"    Transcript too short or missing\")\n",
    "        video['transcript_summary'] = None\n",
    "        video['transcript_sentiment'] = None\n",
    "        return video\n",
    "    \n",
    "    try:\n",
    "        # Clean and truncate transcript\n",
    "        transcript_text = transcript_text.strip()\n",
    "        words = transcript_text.split()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"   Word count: {len(words)}\")\n",
    "        \n",
    "        # BART works best with 100-1024 tokens\n",
    "        if len(words) < 100:\n",
    "            if debug:\n",
    "                print(f\"    Too few words: {len(words)}\")\n",
    "            video['transcript_summary'] = None\n",
    "            video['transcript_sentiment'] = None\n",
    "            return video\n",
    "        \n",
    "        if len(words) > 1000:\n",
    "            transcript_text = ' '.join(words[:1000])\n",
    "            if debug:\n",
    "                print(f\"    Truncated to 1000 words\")\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"   Generating summary...\")\n",
    "            print(f\"   First 200 chars: {transcript_text[:200]}\")\n",
    "        \n",
    "        # Generate summary with better parameters\n",
    "\n",
    "        summary = summarize_long_text(transcript_text)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"   Summary: {summary}\")\n",
    "        \n",
    "        # Sentiment of summary\n",
    "        transcript_sentiment = sentiment_analyzer(summary[:512])[0]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"   Sentiment: {transcript_sentiment}\")\n",
    "        \n",
    "        video['transcript_summary'] = summary\n",
    "        video['transcript_sentiment'] = transcript_sentiment\n",
    "        \n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"   Error: {type(e).__name__}: {str(e)}\")\n",
    "        video['transcript_summary'] = None\n",
    "        try:\n",
    "            video['transcript_sentiment'] = sentiment_analyzer(transcript_text[:512])[0]\n",
    "        except Exception:\n",
    "            video['transcript_sentiment'] = None\n",
    "    \n",
    "    return video\n",
    "\n",
    "# Test on first video with debug output\n",
    "print(\"\\nTesting first video with debug output:\\n\")\n",
    "if youtube_videos_api:\n",
    "    test_video = youtube_videos_api[0].copy()\n",
    "    print(f\"Title: {test_video.get('title')}\")\n",
    "    analyze_video_sentiment(test_video, debug=True)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Ask user if they want to continue\n",
    "response = input(\"Continue with all videos? (y/n): \")\n",
    "\n",
    "if response.lower() == 'y':\n",
    "    print(\"\\n Analyzing all videos...\")\n",
    "    \n",
    "    for video in tqdm(youtube_videos_api, desc=\"Processing videos\", unit=\"video\"):\n",
    "        if video.get('transcript_text'):\n",
    "            analyze_video_sentiment(video, debug=False)\n",
    "        else:\n",
    "            video['title_sentiment'] = None\n",
    "            video['transcript_summary'] = None\n",
    "            video['transcript_sentiment'] = None\n",
    "    \n",
    "    print(\"Analysis complete!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b045b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(videos, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(videos, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# usage\n",
    "save_to_json(youtube_videos_api, \"youtube_analysis.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac76c1",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c37da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_entity(name: str) -> str:\n",
    "    if not name:\n",
    "        return name\n",
    "\n",
    "    n = name.strip().lower()\n",
    "\n",
    "    n = re.sub(r\"^(the|a|an)\\s+\", \"\", n)\n",
    "    n = re.sub(r\"[^\\w\\s]\", \"\", n)\n",
    "    n = re.sub(r\"\\s+\", \" \", n)\n",
    "\n",
    "    if n in ENTITY_ALIASES:\n",
    "        return ENTITY_ALIASES[n]\n",
    "\n",
    "    return n.upper() if n.isupper() else n.title()\n",
    "\n",
    "def sentiment_to_score(sentiment):\n",
    "    if not sentiment:\n",
    "        return None\n",
    "    label = str(sentiment.get('label', '')).upper()\n",
    "    score = float(sentiment.get('score', 0))\n",
    "    if 'POS' in label:\n",
    "        return score\n",
    "    if 'NEG' in label:\n",
    "        return -score\n",
    "    return 0.0\n",
    "\n",
    "def extract_video_text(video, prefer_summary=True):\n",
    "    title = video.get('title', '')\n",
    "    transcript = ''\n",
    "    if prefer_summary and video.get('transcript_summary'):\n",
    "        transcript = video['transcript_summary']\n",
    "    elif video.get('transcript_text'):\n",
    "        transcript = video['transcript_text']\n",
    "    combined = f\"{title} {transcript}\".strip()\n",
    "    return combined\n",
    "\n",
    "def analyze_video_entities_split(video):\n",
    "    title = video.get('title', '') or ''\n",
    "\n",
    "    # Prefer summary, but fall back to full transcript_text if no summary\n",
    "    raw_summary = video.get('transcript_summary') or video.get('transcript_text') or ''\n",
    "    summary = raw_summary\n",
    "\n",
    "    title_doc = nlp(title) if title else None\n",
    "    summary_doc = nlp(summary) if summary else None\n",
    "\n",
    "    title_tickers = set(get_tickers(title)) if title else set()\n",
    "    title_companies = set(get_companies(title_doc)) if title_doc else set()\n",
    "    title_sectors = set(get_sectors(title.lower())) if title else set()\n",
    "\n",
    "    summary_tickers = set(get_tickers(summary)) if summary else set()\n",
    "    summary_companies = set(get_companies(summary_doc)) if summary_doc else set()\n",
    "    summary_sectors = set(get_sectors(summary.lower())) if summary else set()\n",
    "\n",
    "    title_score = sentiment_to_score(video.get('title_sentiment'))\n",
    "    summary_score = sentiment_to_score(video.get('transcript_sentiment'))\n",
    "\n",
    "    return {\n",
    "        \"title\": (title_tickers, title_companies, title_sectors, title_score),\n",
    "        \"summary\": (summary_tickers, summary_companies, summary_sectors, summary_score),\n",
    "    }\n",
    "\n",
    "def aggregate_youtube_entities(videos):\n",
    "\n",
    "    def new_bucket():\n",
    "        return {\n",
    "            \"title_mentions\": 0,\n",
    "            \"title_scores\": [],  # One score per video where entity appears in title\n",
    "            \"summary_mentions\": 0,\n",
    "            \"summary_scores\": [],  # One score per video where entity appears in summary\n",
    "        }\n",
    "\n",
    "    stock_stats = defaultdict(new_bucket)\n",
    "    company_stats = defaultdict(new_bucket)\n",
    "    sector_stats = defaultdict(new_bucket)\n",
    "\n",
    "    for video in videos:\n",
    "        parts = analyze_video_entities_split(video)\n",
    "\n",
    "        # Track which entities we've already counted for this video (per part)\n",
    "        # to avoid adding the same score multiple times\n",
    "        title_entities_seen = set()\n",
    "        summary_entities_seen = set()\n",
    "\n",
    "        for part_name, (tickers, companies, sectors, score) in parts.items():\n",
    "            is_title = (part_name == \"title\")\n",
    "            seen_set = title_entities_seen if is_title else summary_entities_seen\n",
    "\n",
    "            for t in tickers:\n",
    "                t = normalize_entity(t)\n",
    "                stock_stats[t][f\"{part_name}_mentions\"] += 1\n",
    "                # Only add score once per video per part\n",
    "                if t not in seen_set and score is not None:\n",
    "                    stock_stats[t][f\"{part_name}_scores\"].append(score)\n",
    "                    seen_set.add(t)\n",
    "\n",
    "            for c in companies:\n",
    "                c = normalize_entity(c)\n",
    "                company_stats[c][f\"{part_name}_mentions\"] += 1\n",
    "                # Only add score once per video per part\n",
    "                if c not in seen_set and score is not None:\n",
    "                    company_stats[c][f\"{part_name}_scores\"].append(score)\n",
    "                    seen_set.add(c)\n",
    "\n",
    "            for s in sectors:\n",
    "                s = normalize_entity(s)\n",
    "                sector_stats[s][f\"{part_name}_mentions\"] += 1\n",
    "                # Only add score once per video per part\n",
    "                if s not in seen_set and score is not None:\n",
    "                    sector_stats[s][f\"{part_name}_scores\"].append(score)\n",
    "                    seen_set.add(s)\n",
    "\n",
    "    def finalize(stats):\n",
    "        rows = []\n",
    "        for name, data in stats.items():\n",
    "            rows.append({\n",
    "                \"name\": name,\n",
    "\n",
    "                \"title_mentions\": data[\"title_mentions\"],\n",
    "                \"avg_title_sentiment\": (\n",
    "                    sum(data[\"title_scores\"]) / len(data[\"title_scores\"])\n",
    "                    if data[\"title_scores\"] else None\n",
    "                ),\n",
    "\n",
    "                \"summary_mentions\": data[\"summary_mentions\"],\n",
    "                \"avg_summary_sentiment\": (\n",
    "                    sum(data[\"summary_scores\"]) / len(data[\"summary_scores\"])\n",
    "                    if data[\"summary_scores\"] else None\n",
    "                ),\n",
    "            })\n",
    "\n",
    "        rows.sort(key=lambda x: (x[\"title_mentions\"] + x[\"summary_mentions\"]), reverse=True)\n",
    "        return rows\n",
    "\n",
    "    return {\n",
    "        \"stocks\": finalize(stock_stats),\n",
    "        \"companies\": finalize(company_stats),\n",
    "        \"sectors\": finalize(sector_stats),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8984daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = aggregate_youtube_entities(youtube_videos_api)\n",
    "save_to_json(result, \"entity_mentions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['companies']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665887a",
   "metadata": {},
   "source": [
    "## Turn Mentions into readable txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "599f717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sentiment(score):\n",
    "    \"\"\"Format sentiment score for display.\"\"\"\n",
    "    if score is None:\n",
    "        return \"N/A\"\n",
    "    return f\"{score:+.4f}\"\n",
    "\n",
    "def format_mentions(item):\n",
    "    \"\"\"Format a single item's mention data.\"\"\"\n",
    "    total_mentions = item.get(\"title_mentions\", 0) + item.get(\"summary_mentions\", 0)\n",
    "    title_sent = format_sentiment(item.get(\"avg_title_sentiment\"))\n",
    "    summary_sent = format_sentiment(item.get(\"avg_summary_sentiment\"))\n",
    "    \n",
    "    lines = [\n",
    "        f\"  Name: {item['name']}\",\n",
    "        f\"  Total Mentions: {total_mentions}\",\n",
    "        f\"    - Title Mentions: {item.get('title_mentions', 0)} (Sentiment: {title_sent})\",\n",
    "        f\"    - Summary Mentions: {item.get('summary_mentions', 0)} (Sentiment: {summary_sent})\"\n",
    "    ]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daebda35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTITY MENTIONS REPORT\n",
      "================================================================================\n",
      "\n",
      "STOCKS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1.   Name: Ai\n",
      "  Total Mentions: 27\n",
      "    - Title Mentions: 13 (Sentiment: +0.0979)\n",
      "    - Summary Mentions: 14 (Sentiment: -0.0071)\n",
      "\n",
      "2.   Name: Ceo\n",
      "  Total Mentions: 20\n",
      "    - Title Mentions: 8 (Sentiment: +0.1248)\n",
      "    - Summary Mentions: 12 (Sentiment: -0.1406)\n",
      "\n",
      "3.   Name: CNN\n",
      "  Total Mentions: 8\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 8 (Sentiment: -0.0813)\n",
      "\n",
      "4.   Name: Federal Reserve\n",
      "  Total Mentions: 8\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 8 (Sentiment: -0.2793)\n",
      "\n",
      "5.   Name: Cnbc\n",
      "  Total Mentions: 5\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 4 (Sentiment: +0.0000)\n",
      "\n",
      "6.   Name: More\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 4 (Sentiment: +0.1979)\n",
      "\n",
      "7.   Name: Down\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 4 (Sentiment: -0.9384)\n",
      "\n",
      "8.   Name: Department of Justice\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 2 (Sentiment: -0.8320)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.6333)\n",
      "\n",
      "9.   Name: Lz\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 4 (Sentiment: -0.1473)\n",
      "\n",
      "10.   Name: New\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.3233)\n",
      "\n",
      "11.   Name: Right\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.3220)\n",
      "\n",
      "12.   Name: Off\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.0205)\n",
      "\n",
      "13.   Name: Today\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.6217)\n",
      "\n",
      "14.   Name: Look\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.3141)\n",
      "\n",
      "15.   Name: Jay\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.2983)\n",
      "\n",
      "16.   Name: Rate\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: +0.1423)\n",
      "\n",
      "17.   Name: Et\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.3087)\n",
      "\n",
      "18.   Name: Us\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.1757)\n",
      "\n",
      "19.   Name: You\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "20.   Name: Jp\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.7972)\n",
      "\n",
      "21.   Name: Over\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.9700)\n",
      "\n",
      "22.   Name: Here\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.8792)\n",
      "\n",
      "23.   Name: Up\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.7885)\n",
      "\n",
      "24.   Name: Five\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.5891)\n",
      "\n",
      "25.   Name: So\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: N/A)\n",
      "\n",
      "26.   Name: We\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.8229)\n",
      "\n",
      "27.   Name: Tim\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "28.   Name: Tech\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.4850)\n",
      "\n",
      "29.   Name: Th\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.4850)\n",
      "\n",
      "30.   Name: Ahead\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "31.   Name: Net\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.0674)\n",
      "\n",
      "32.   Name: Now\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.4829)\n",
      "\n",
      "33.   Name: Cap\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.0647)\n",
      "\n",
      "34.   Name: Xai\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "35.   Name: Below\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.9253)\n",
      "\n",
      "36.   Name: This\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.9168)\n",
      "\n",
      "37.   Name: Elon\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "38.   Name: Musk\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "39.   Name: Pbs\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "40.   Name: Per\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.4630)\n",
      "\n",
      "41.   Name: Court\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.4475)\n",
      "\n",
      "42.   Name: David\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "43.   Name: Eamon\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.4475)\n",
      "\n",
      "44.   Name: Cto\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 2 (Sentiment: +0.8166)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "45.   Name: Ppi\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 1 (Sentiment: -0.9156)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.7533)\n",
      "\n",
      "46.   Name: Ten\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.3767)\n",
      "\n",
      "47.   Name: Biden\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.2569)\n",
      "\n",
      "48.   Name: They\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.1821)\n",
      "\n",
      "49.   Name: Bank\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.1821)\n",
      "\n",
      "50.   Name: Wells\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.1567)\n",
      "\n",
      "51.   Name: Fargo\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.1567)\n",
      "\n",
      "52.   Name: Mntn\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: -0.9646)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "53.   Name: Back\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "54.   Name: Round\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "55.   Name: Jim\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "56.   Name: Speak\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "57.   Name: Larry\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "58.   Name: Live\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "59.   Name: Rig\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "60.   Name: El\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "61.   Name: Xom\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "62.   Name: Few\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "63.   Name: Color\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "64.   Name: Seems\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "65.   Name: Need\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "66.   Name: Go\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "67.   Name: Exxon\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "68.   Name: Ve\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "69.   Name: Did\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "70.   Name: Like\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "71.   Name: If\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "72.   Name: Karen\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "73.   Name: Last\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "74.   Name: Left\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "75.   Name: Days\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "76.   Name: Estee\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "77.   Name: Yes\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "78.   Name: Two\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "79.   Name: Humor\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "80.   Name: Think\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "81.   Name: Had\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "82.   Name: Got\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "83.   Name: Ellis\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "84.   Name: Lulu\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "85.   Name: Alice\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "86.   Name: Aon\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "87.   Name: Mocha\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "88.   Name: Acr\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "89.   Name: Mo\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "90.   Name: Debt\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "91.   Name: Peak\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "92.   Name: Set\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "93.   Name: Real\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "94.   Name: Adobe\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5899)\n",
      "\n",
      "95.   Name: His\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9700)\n",
      "\n",
      "96.   Name: Etf\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9700)\n",
      "\n",
      "97.   Name: Call\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9700)\n",
      "\n",
      "98.   Name: Chart\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9700)\n",
      "\n",
      "99.   Name: Oil\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "100.   Name: Pippa\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "101.   Name: Flow\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "102.   Name: Place\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "103.   Name: Iraqi\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "104.   Name: Might\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "105.   Name: Where\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "106.   Name: Fomc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "107.   Name: Mw\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5635)\n",
      "\n",
      "108.   Name: Major\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.8907)\n",
      "\n",
      "109.   Name: Level\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.8907)\n",
      "\n",
      "110.   Name: Wi\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.8975)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "111.   Name: Ipo\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "112.   Name: Sean\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "113.   Name: Kbw\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.9051)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "114.   Name: Want\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.8229)\n",
      "\n",
      "115.   Name: See\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.8229)\n",
      "\n",
      "116.   Name: Obbb\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "117.   Name: Being\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "118.   Name: Kar\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "119.   Name: Trade\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "120.   Name: Vi\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5981)\n",
      "\n",
      "121.   Name: Lyles\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5981)\n",
      "\n",
      "122.   Name: Nucor\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5981)\n",
      "\n",
      "123.   Name: Mayor\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5981)\n",
      "\n",
      "124.   Name: Ready\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5981)\n",
      "\n",
      "125.   Name: Nato\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6320)\n",
      "\n",
      "126.   Name: Book\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9424)\n",
      "\n",
      "127.   Name: Looms\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9424)\n",
      "\n",
      "128.   Name: Beige\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9424)\n",
      "\n",
      "129.   Name: Train\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "130.   Name: Needs\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "131.   Name: China\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "132.   Name: Chips\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "133.   Name: Sales\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "134.   Name: Bound\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "135.   Name: Green\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "136.   Name: Light\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "137.   Name: Model\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "138.   Name: Gpu\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "139.   Name: Makes\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "140.   Name: Plus\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "141.   Name: All\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "142.   Name: Those\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "143.   Name: Start\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "144.   Name: Than\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "145.   Name: Sprin\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "146.   Name: Could\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "147.   Name: Vp\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "148.   Name: Jpm\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.5530)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "149.   Name: Kelly\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6408)\n",
      "\n",
      "150.   Name: Kell\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6408)\n",
      "\n",
      "151.   Name: Hike\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6408)\n",
      "\n",
      "152.   Name: Chief\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6408)\n",
      "\n",
      "153.   Name: Nancy\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6861)\n",
      "\n",
      "154.   Name: Mike\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6861)\n",
      "\n",
      "155.   Name: Large\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "156.   Name: Scale\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "157.   Name: Fcc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6372)\n",
      "\n",
      "158.   Name: Gop\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.7651)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "159.   Name: Pains\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.4843)\n",
      "\n",
      "160.   Name: Lseg\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.4843)\n",
      "\n",
      "161.   Name: Plc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "162.   Name: Rjf\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "163.   Name: Cnx\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "164.   Name: Iym\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "165.   Name: Gld\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "166.   Name: Half\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9261)\n",
      "\n",
      "167.   Name: Seema\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9669)\n",
      "\n",
      "168.   Name: Mody\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9669)\n",
      "\n",
      "169.   Name: Cfo\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "170.   Name: Dws\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "171.   Name: Check\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "172.   Name: Bosa\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "173.   Name: Talks\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "174.   Name: Self\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "175.   Name: Full\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "176.   Name: Month\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "177.   Name: Tesla\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "178.   Name: Hour\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9168)\n",
      "\n",
      "179.   Name: Stock\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9168)\n",
      "\n",
      "180.   Name: Vote\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9168)\n",
      "\n",
      "181.   Name: Ban\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9168)\n",
      "\n",
      "182.   Name: Gress\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9168)\n",
      "\n",
      "183.   Name: Close\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "184.   Name: Value\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "185.   Name: Such\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "186.   Name: Sort\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "187.   Name: Fair\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "188.   Name: Still\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "189.   Name: Both\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "190.   Name: Cpi\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "191.   Name: Pause\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "192.   Name: Diana\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "193.   Name: Rick\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "194.   Name: Henry\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "195.   Name: Olick\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "196.   Name: Bt\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "197.   Name: Await\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8950)\n",
      "\n",
      "198.   Name: Chair\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8950)\n",
      "\n",
      "199.   Name: Pile\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8950)\n",
      "\n",
      "200.   Name: Cost\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.7885)\n",
      "\n",
      "201.   Name: Awake\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "202.   Name: Ahmed\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "203.   Name: META\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "204.   Name: Llama\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "205.   Name: Each\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5891)\n",
      "\n",
      "206.   Name: City\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5891)\n",
      "\n",
      "207.   Name: Shaun\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5848)\n",
      "\n",
      "208.   Name: Act\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5848)\n",
      "\n",
      "209.   Name: Scott\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "210.   Name: Cryp\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "211.   Name: Hill\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "212.   Name: Amos\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5138)\n",
      "\n",
      "213.   Name: Away\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "214.   Name: Years\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "215.   Name: Dual\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "216.   Name: Hatha\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "217.   Name: Money\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "218.   Name: Some\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "219.   Name: Give\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "220.   Name: Grow\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5936)\n",
      "\n",
      "221.   Name: Gets\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5936)\n",
      "\n",
      "222.   Name: Rotc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5936)\n",
      "\n",
      "223.   Name: Citi\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5936)\n",
      "\n",
      "224.   Name: Fixed\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9253)\n",
      "\n",
      "225.   Name: Sunk\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9253)\n",
      "\n",
      "226.   Name: Lost\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "227.   Name: Basis\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9578)\n",
      "\n",
      "228.   Name: Bak\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9578)\n",
      "\n",
      "229.   Name: Ratio\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9578)\n",
      "\n",
      "230.   Name: These\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9578)\n",
      "\n",
      "231.   Name: Nii\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.6526)\n",
      "\n",
      "232.   Name: Asset\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.6526)\n",
      "\n",
      "233.   Name: Aei\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.7040)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "234.   Name: Pnc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9298)\n",
      "\n",
      "235.   Name: Bros\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "236.   Name: Comp\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "237.   Name: Par\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "238.   Name: Bid\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "239.   Name: Ount\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "240.   Name: Tv\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "241.   Name: Br\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "242.   Name: Cable\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "243.   Name: Plans\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "244.   Name: Sell\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "245.   Name: Coca\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "246.   Name: Costa\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "247.   Name: Chain\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "248.   Name: Saks\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "249.   Name: Cola\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "250.   Name: About\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "251.   Name: Store\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "252.   Name: Wef\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "253.   Name: Loss\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "254.   Name: Glp\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "255.   Name: Amgen\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "256.   Name: One\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "\n",
      "COMPANIES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1.   Name: Federal Reserve\n",
      "  Total Mentions: 21\n",
      "    - Title Mentions: 7 (Sentiment: -0.1578)\n",
      "    - Summary Mentions: 14 (Sentiment: -0.2600)\n",
      "\n",
      "2.   Name: Bank Of America\n",
      "  Total Mentions: 6\n",
      "    - Title Mentions: 3 (Sentiment: +0.3696)\n",
      "    - Summary Mentions: 3 (Sentiment: +0.1921)\n",
      "\n",
      "3.   Name: Supreme Court\n",
      "  Total Mentions: 6\n",
      "    - Title Mentions: 2 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 4 (Sentiment: -0.4222)\n",
      "\n",
      "4.   Name: Cnbc\n",
      "  Total Mentions: 5\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 4 (Sentiment: N/A)\n",
      "\n",
      "5.   Name: White House\n",
      "  Total Mentions: 5\n",
      "    - Title Mentions: 2 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.2931)\n",
      "\n",
      "6.   Name: Warner Bros\n",
      "  Total Mentions: 5\n",
      "    - Title Mentions: 2 (Sentiment: +0.4628)\n",
      "    - Summary Mentions: 3 (Sentiment: +0.0000)\n",
      "\n",
      "7.   Name: Wells Fargo\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 1 (Sentiment: -0.7908)\n",
      "    - Summary Mentions: 3 (Sentiment: +0.0975)\n",
      "\n",
      "8.   Name: CNN\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 4 (Sentiment: N/A)\n",
      "\n",
      "9.   Name: Cnncom\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 4 (Sentiment: +0.0690)\n",
      "\n",
      "10.   Name: Netflix\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 2 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "11.   Name: House\n",
      "  Total Mentions: 4\n",
      "    - Title Mentions: 3 (Sentiment: +0.2550)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.4776)\n",
      "\n",
      "12.   Name: AAPL\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.1318)\n",
      "\n",
      "13.   Name: Ai\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: N/A)\n",
      "\n",
      "14.   Name: Openai\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 1 (Sentiment: +0.7008)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.2817)\n",
      "\n",
      "15.   Name: Congress\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.2111)\n",
      "\n",
      "16.   Name: Trump\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 1 (Sentiment: +0.9346)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.6333)\n",
      "\n",
      "17.   Name: Jp Morgan\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: -0.7972)\n",
      "\n",
      "18.   Name: Software\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 2 (Sentiment: +0.0616)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "19.   Name: Adobe\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.5564)\n",
      "\n",
      "20.   Name: Dallas Fed\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "21.   Name: Travel Snapshots\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "22.   Name: Pbs\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: N/A)\n",
      "\n",
      "23.   Name: Department of Justice\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: N/A)\n",
      "\n",
      "24.   Name: Cto\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 2 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "25.   Name: Citigroup\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 2 (Sentiment: -0.7230)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "26.   Name: Goldman Sachs\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9517)\n",
      "\n",
      "27.   Name: Rig\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "28.   Name: Xom\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "29.   Name: Descartes\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "30.   Name: Lulu\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "31.   Name: Mo Ellis\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "32.   Name: Aon\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "33.   Name: Mocha Acronym\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.6773)\n",
      "\n",
      "34.   Name: Commercial Real Estate\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "35.   Name: Chart\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: -0.6825)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "36.   Name: Chart Master\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9700)\n",
      "\n",
      "37.   Name: New Fed Chair\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "38.   Name: Powell\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "39.   Name: Us Trade Rep\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "40.   Name: Ariels Charles Bobrinskoy Oil\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.8810)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "41.   Name: Exxon\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "42.   Name: Chevron\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "43.   Name: Cerebras\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.7008)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "44.   Name: Broadcom\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5635)\n",
      "\n",
      "45.   Name: Cerebrus\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5635)\n",
      "\n",
      "46.   Name: Macro Risk Advisors\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "47.   Name: Rotations\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.8907)\n",
      "\n",
      "48.   Name: Ipo\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "49.   Name: Venture\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "50.   Name: Kbw\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "51.   Name: Coinbase\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "52.   Name: Oval Office\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "53.   Name: Morgan Stanleys\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "54.   Name: Losers\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "55.   Name: Nucor\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "56.   Name: Charlotte\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5981)\n",
      "\n",
      "57.   Name: Vi Lyles\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5981)\n",
      "\n",
      "58.   Name: Nato\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "59.   Name: Banks Of America\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.7820)\n",
      "\n",
      "60.   Name: Cap\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "61.   Name: Chinese Ai\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "62.   Name: Narrative\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "63.   Name: Serhant Real Estates\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.7444)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "64.   Name: Vp Vance And Rubio At\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "65.   Name: Warner Brothers Discovery\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "66.   Name: Jpmorgan\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.5530)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "67.   Name: Kelly\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "68.   Name: Nancy\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "69.   Name: Federal Communications Commission\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "70.   Name: Fcc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "71.   Name: Gop\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "72.   Name: Investment Committee\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "73.   Name: Linde Plc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "74.   Name: Rjf\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "75.   Name: Cnx\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "76.   Name: Iym\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "77.   Name: Gld\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "78.   Name: Nasdaq\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9261)\n",
      "\n",
      "79.   Name: Wells Fargo Cfo\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "80.   Name: Q4\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "81.   Name: Dws Groups\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "82.   Name: Bain\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8401)\n",
      "\n",
      "83.   Name: Saks\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8401)\n",
      "\n",
      "84.   Name: Full Selfdriving\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "85.   Name: Vehicles\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "86.   Name: Monthly Subscription\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "87.   Name: Trumps Actions\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "88.   Name: Congress Kicking Off Initial\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.9168)\n",
      "\n",
      "89.   Name: Warner\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "90.   Name: Cleveland Fed\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: -0.3744)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "91.   Name: Philadelphia Fed\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: -0.9114)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "92.   Name: Airbnb\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "93.   Name: Opinion\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8950)\n",
      "\n",
      "94.   Name: Tariffs\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8950)\n",
      "\n",
      "95.   Name: Pile On Insults\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.8950)\n",
      "\n",
      "96.   Name: Cost\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "97.   Name: META\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "98.   Name: GOOGL\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "99.   Name: Ahmed\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "100.   Name: American Gaming Association\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5848)\n",
      "\n",
      "101.   Name: Responsible Actors\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5848)\n",
      "\n",
      "102.   Name: Federally Regulated\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.5848)\n",
      "\n",
      "103.   Name: Markup\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "104.   Name: Philanthropy\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "105.   Name: Control\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "106.   Name: Hightower\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "107.   Name: Morgan Stanley\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.5936)\n",
      "\n",
      "108.   Name: Citi\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "109.   Name: Harvard\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "110.   Name: Us Bank Of America\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9578)\n",
      "\n",
      "111.   Name: Bak\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "112.   Name: Nii\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "113.   Name: Burson\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "114.   Name: Aei\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: N/A)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "115.   Name: Pnc\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "116.   Name: Warner Bros Discovery\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "117.   Name: Skydance\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "118.   Name: Paramount\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "119.   Name: Cable Tv Channels\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "120.   Name: Luxury Department\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "121.   Name: Wells Fargo Shares\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "122.   Name: Cocacola Is Scrapping Plans\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: -0.9659)\n",
      "\n",
      "123.   Name: Marsh\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "124.   Name: Texas Instruments\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "125.   Name: Amgen\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "126.   Name: Glp\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: N/A)\n",
      "\n",
      "127.   Name: Eli Liy\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 1 (Sentiment: +0.0000)\n",
      "\n",
      "\n",
      "SECTORS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1.   Name: Finance\n",
      "  Total Mentions: 79\n",
      "    - Title Mentions: 36 (Sentiment: +0.0573)\n",
      "    - Summary Mentions: 43 (Sentiment: -0.1066)\n",
      "\n",
      "2.   Name: Technology\n",
      "  Total Mentions: 68\n",
      "    - Title Mentions: 22 (Sentiment: +0.1051)\n",
      "    - Summary Mentions: 46 (Sentiment: -0.1563)\n",
      "\n",
      "3.   Name: Automotive\n",
      "  Total Mentions: 49\n",
      "    - Title Mentions: 16 (Sentiment: -0.0725)\n",
      "    - Summary Mentions: 33 (Sentiment: -0.1861)\n",
      "\n",
      "4.   Name: Real Estate\n",
      "  Total Mentions: 11\n",
      "    - Title Mentions: 4 (Sentiment: +0.2540)\n",
      "    - Summary Mentions: 7 (Sentiment: +0.2229)\n",
      "\n",
      "5.   Name: Energy\n",
      "  Total Mentions: 11\n",
      "    - Title Mentions: 4 (Sentiment: +0.2219)\n",
      "    - Summary Mentions: 7 (Sentiment: -0.0413)\n",
      "\n",
      "6.   Name: Retail\n",
      "  Total Mentions: 10\n",
      "    - Title Mentions: 5 (Sentiment: +0.3624)\n",
      "    - Summary Mentions: 5 (Sentiment: -0.3156)\n",
      "\n",
      "7.   Name: Aerospace\n",
      "  Total Mentions: 3\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 3 (Sentiment: -0.2107)\n",
      "\n",
      "8.   Name: Healthcare\n",
      "  Total Mentions: 2\n",
      "    - Title Mentions: 0 (Sentiment: N/A)\n",
      "    - Summary Mentions: 2 (Sentiment: +0.0000)\n",
      "\n",
      "9.   Name: Telecommunications\n",
      "  Total Mentions: 1\n",
      "    - Title Mentions: 1 (Sentiment: +0.0000)\n",
      "    - Summary Mentions: 0 (Sentiment: N/A)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "json_path = Path(\"entity_mentions.json\")\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Build the output text\n",
    "output_lines = []\n",
    "output_lines.append(\"=\" * 80)\n",
    "output_lines.append(\"ENTITY MENTIONS REPORT\")\n",
    "output_lines.append(\"=\" * 80)\n",
    "output_lines.append(\"\")\n",
    "\n",
    "# Stocks Section\n",
    "output_lines.append(\"STOCKS\")\n",
    "output_lines.append(\"-\" * 80)\n",
    "if data.get(\"stocks\"):\n",
    "    for i, stock in enumerate(data[\"stocks\"], 1):\n",
    "        output_lines.append(f\"\\n{i}. {format_mentions(stock)}\")\n",
    "else:\n",
    "    output_lines.append(\"  No stocks found.\")\n",
    "output_lines.append(\"\")\n",
    "output_lines.append(\"\")\n",
    "\n",
    "# Companies Section\n",
    "output_lines.append(\"COMPANIES\")\n",
    "output_lines.append(\"-\" * 80)\n",
    "if data.get(\"companies\"):\n",
    "    for i, company in enumerate(data[\"companies\"], 1):\n",
    "        output_lines.append(f\"\\n{i}. {format_mentions(company)}\")\n",
    "else:\n",
    "    output_lines.append(\"  No companies found.\")\n",
    "output_lines.append(\"\")\n",
    "output_lines.append(\"\")\n",
    "\n",
    "# Sectors Section\n",
    "output_lines.append(\"SECTORS\")\n",
    "output_lines.append(\"-\" * 80)\n",
    "if data.get(\"sectors\"):\n",
    "    for i, sector in enumerate(data[\"sectors\"], 1):\n",
    "        output_lines.append(f\"\\n{i}. {format_mentions(sector)}\")\n",
    "else:\n",
    "    output_lines.append(\"  No sectors found.\")\n",
    "\n",
    "output_lines.append(\"\")\n",
    "output_lines.append(\"=\" * 80)\n",
    "\n",
    "# Join all lines\n",
    "output_text = \"\\n\".join(output_lines)\n",
    "\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdbf4eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to entity_mentions.txt\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"entity_mentions.txt\")\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_text)\n",
    "\n",
    "print(f\"Successfully saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def28e16",
   "metadata": {},
   "source": [
    "# Filter by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('100vids.json', 'r', encoding='utf-8') as file:\n",
    "    # Use json.load() to convert the file content to a Python object\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def filter_by_date_range(videos, chosen_date_str):\n",
    "    \"\"\"\n",
    "    chosen_date_str format: 'YYYY-MM-DD'\n",
    "    \"\"\"\n",
    "    chosen_date = datetime.strptime(chosen_date_str, \"%Y-%m-%d\")\n",
    "    start_date = chosen_date - timedelta(days=7)\n",
    "\n",
    "    filtered = []\n",
    "\n",
    "    for v in videos:\n",
    "        published_str = v.get(\"published\") or v.get(\"published_date\")\n",
    "        if not published_str:\n",
    "            continue\n",
    "\n",
    "        published_dt = datetime.fromisoformat(published_str.replace(\"Z\", \"\"))\n",
    "\n",
    "        if start_date <= published_dt <= chosen_date:\n",
    "            filtered.append(v)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a705a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_date = \"2026-01-15\"\n",
    "\n",
    "filtered_videos = filter_by_date_range(data, chosen_date)\n",
    "filtered_videos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
